{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to libhal Warning libhal is still in BETA ! Abstract libhal exists to make hardware drivers \ud83d\ude9a portable , \ud83e\uddbe flexible , \ud83d\udce6 accessible , and \ud83c\udf70 easy to use . libhal seeks to provide a foundation for embedded drivers, allowing those drivers to be used across different processors, microcontrollers, systems, and devices. The design philosophy of libhal is to be: Multi Targeted Light Weight General Minimalist Safe Tested & Testable Compiled Quickly OS Agnostic The Basics libhal, at its core, is simply a set of interfaces that correspond to hardware devices and peripherals. These interfaces use runtime polymorphism in order to decouple application logic from driver implementation details. This decoupling enables applications to run on any target device that has the necessary components available. A quick example is a blinker program. The required interfaces for such a program is a hal::output_pin for controlling the LED and a hal::steady_clock for keeping time. Now your application takes both of these drivers without having to consider their implementation details and blink and LED at a specified interval. Below is a set of source code to make an application that can work with both the lpc40xx and stm32f10x microcontroller. blinker.cpp hardware_map.hpp main.cpp lpc40.cpp stm32f10.cpp #include <libhal-util/steady_clock.hpp> #include \"hardware_map.hpp\" hal :: status application ( starter :: hardware_map & p_map ) { using namespace std :: chrono_literals ; using namespace hal :: literals ; while ( true ) { HAL_CHECK ( p_map . led -> level ( true )); HAL_CHECK ( hal :: delay ( * p_map . steady_clock , 500 ms )); HAL_CHECK ( p_map . led -> level ( false )); HAL_CHECK ( hal :: delay ( * p_map . steady_clock , 500 ms )); } return hal :: success (); } #pragma once #include <functional> #include <libhal/output_pin.hpp> #include <libhal/steady_clock.hpp> namespace starter { struct hardware_map { hal :: output_pin * led ; hal :: steady_clock * steady_clock ; std :: function < void () > reset ; }; } // namespace starter // Application function must be implemented by one of the compilation units // (.cpp) files. hal :: status application ( starter :: hardware_map & p_map ); hal :: result < starter :: hardware_map > initialize_target (); #include \"hardware_map.hpp\" int main () { auto init_result = initialize_target (); if ( ! init_result ) { hal :: halt (); } auto hardware_map = init_result . value (); auto is_finished = application ( hardware_map ); if ( ! is_finished ) { hardware_map . reset (); } else { hal :: halt (); } return 0 ; } namespace boost { void throw_exception ([[ maybe_unused ]] std :: exception const & p_error ) { std :: abort (); } } // namespace boost #include <libhal-armcortex/dwt_counter.hpp> #include <libhal-armcortex/startup.hpp> #include <libhal-armcortex/system_control.hpp> #include <libhal-lpc40/output_pin.hpp> #include \"hardware_map.hpp\" hal :: result < starter :: hardware_map > initialize_target () { hal :: cortex_m :: initialize_data_section (); hal :: cortex_m :: system_control :: initialize_floating_point_unit (); auto & led = HAL_CHECK (( hal :: lpc40xx :: output_pin :: get < 1 , 18 > ())); return starter :: hardware_map { . led = & led , . steady_clock = & counter , . reset = []() { hal :: cortex_m :: system_control :: reset (); }, }; } #include <libhal-armcortex/dwt_counter.hpp> #include <libhal-armcortex/startup.hpp> #include <libhal-armcortex/system_control.hpp> #include <libhal-stm32f10x/output_pin.hpp> #include \"hardware_map.hpp\" hal :: result < starter :: hardware_map > initialize_target () { hal :: cortex_m :: initialize_data_section (); auto & led = HAL_CHECK (( hal :: stm32f10x :: output_pin :: get < 'C' , 13 > ())); return starter :: hardware_map { . led = & led , . steady_clock = & counter , . reset = []() { hal :: cortex_m :: system_control :: reset (); }, }; } Support libhal discord server (preferred) GitHub issues Cpplang Slack #embedded channel Distribution Conan package manager Source code is hosted on GitHub vcpkg (coming soon) package manager There are plans to support to more C++ package managers","title":"\ud83c\udfe1 Home"},{"location":"#abstract","text":"libhal exists to make hardware drivers \ud83d\ude9a portable , \ud83e\uddbe flexible , \ud83d\udce6 accessible , and \ud83c\udf70 easy to use . libhal seeks to provide a foundation for embedded drivers, allowing those drivers to be used across different processors, microcontrollers, systems, and devices. The design philosophy of libhal is to be: Multi Targeted Light Weight General Minimalist Safe Tested & Testable Compiled Quickly OS Agnostic","title":"Abstract"},{"location":"#the-basics","text":"libhal, at its core, is simply a set of interfaces that correspond to hardware devices and peripherals. These interfaces use runtime polymorphism in order to decouple application logic from driver implementation details. This decoupling enables applications to run on any target device that has the necessary components available. A quick example is a blinker program. The required interfaces for such a program is a hal::output_pin for controlling the LED and a hal::steady_clock for keeping time. Now your application takes both of these drivers without having to consider their implementation details and blink and LED at a specified interval. Below is a set of source code to make an application that can work with both the lpc40xx and stm32f10x microcontroller. blinker.cpp hardware_map.hpp main.cpp lpc40.cpp stm32f10.cpp #include <libhal-util/steady_clock.hpp> #include \"hardware_map.hpp\" hal :: status application ( starter :: hardware_map & p_map ) { using namespace std :: chrono_literals ; using namespace hal :: literals ; while ( true ) { HAL_CHECK ( p_map . led -> level ( true )); HAL_CHECK ( hal :: delay ( * p_map . steady_clock , 500 ms )); HAL_CHECK ( p_map . led -> level ( false )); HAL_CHECK ( hal :: delay ( * p_map . steady_clock , 500 ms )); } return hal :: success (); } #pragma once #include <functional> #include <libhal/output_pin.hpp> #include <libhal/steady_clock.hpp> namespace starter { struct hardware_map { hal :: output_pin * led ; hal :: steady_clock * steady_clock ; std :: function < void () > reset ; }; } // namespace starter // Application function must be implemented by one of the compilation units // (.cpp) files. hal :: status application ( starter :: hardware_map & p_map ); hal :: result < starter :: hardware_map > initialize_target (); #include \"hardware_map.hpp\" int main () { auto init_result = initialize_target (); if ( ! init_result ) { hal :: halt (); } auto hardware_map = init_result . value (); auto is_finished = application ( hardware_map ); if ( ! is_finished ) { hardware_map . reset (); } else { hal :: halt (); } return 0 ; } namespace boost { void throw_exception ([[ maybe_unused ]] std :: exception const & p_error ) { std :: abort (); } } // namespace boost #include <libhal-armcortex/dwt_counter.hpp> #include <libhal-armcortex/startup.hpp> #include <libhal-armcortex/system_control.hpp> #include <libhal-lpc40/output_pin.hpp> #include \"hardware_map.hpp\" hal :: result < starter :: hardware_map > initialize_target () { hal :: cortex_m :: initialize_data_section (); hal :: cortex_m :: system_control :: initialize_floating_point_unit (); auto & led = HAL_CHECK (( hal :: lpc40xx :: output_pin :: get < 1 , 18 > ())); return starter :: hardware_map { . led = & led , . steady_clock = & counter , . reset = []() { hal :: cortex_m :: system_control :: reset (); }, }; } #include <libhal-armcortex/dwt_counter.hpp> #include <libhal-armcortex/startup.hpp> #include <libhal-armcortex/system_control.hpp> #include <libhal-stm32f10x/output_pin.hpp> #include \"hardware_map.hpp\" hal :: result < starter :: hardware_map > initialize_target () { hal :: cortex_m :: initialize_data_section (); auto & led = HAL_CHECK (( hal :: stm32f10x :: output_pin :: get < 'C' , 13 > ())); return starter :: hardware_map { . led = & led , . steady_clock = & counter , . reset = []() { hal :: cortex_m :: system_control :: reset (); }, }; }","title":"The Basics"},{"location":"#support","text":"libhal discord server (preferred) GitHub issues Cpplang Slack #embedded channel","title":"Support"},{"location":"#distribution","text":"Conan package manager Source code is hosted on GitHub vcpkg (coming soon) package manager There are plans to support to more C++ package managers","title":"Distribution"},{"location":"about/","text":"About The world of embedded systems is written almost entirely in C and C++. More and more of the embedded world move away from C and towards C++. This has to do with the many benefits of C++ such as type safety, compile time features, meta-programming, multi-paradigm and much more. When these features are used correctly, they can result in smaller binary sizes and higher performance code than in C. But a problem that embedded C++ software suffers is that there isn't a consistent and common API for embedded libraries. Looking around, you will find that each hardware vendor has their own set of libraries and tools for their specific products. If you write a driver on top of their libraries, you will find that your code will only work for that specific platform/product. In some cases you may also be limited to just their toolchain. You as the developer are locked in to this one specific setup. And if you move to another platform, you must do the work of rewriting all of your code again. libhal seeks to solve this issue by creating a set of generic interfaces for embedded system concepts such as serial communication (UART), analog to digital conversion (ADC), inertial measurement units (IMU), pulse width modulation (PWM) and much more. The advantage of building a system on top of libhal is that higher level drivers can be used with any target platform whether it is a stm32, a nxp micro controller, a RISC-V, or is on an embedded linux. This project is inspired by the work of Rust's embedded_hal and follows many of the same design goals. libhal's design goals: Serve as a foundation for building an ecosystem of platform agnostic drivers. Must abstract away device specific details like registers and bitmaps. Must be generic across devices such that any platform can be supported. Must be minimal for boosting performance and reducing size costs. Must be composable such that higher level drivers can build on top of these. Be accessible through package mangers so that developers can easily pick and choose which drivers they want to use. Software Copyrights This source code is licensed under the Apache License 2.0 as described in the LICENSE file. Third Party Library Licenses Boost.LEAF , BOOST license tl-function-ref/1.0.0 , CC0","title":"\ud83e\uddd0 About"},{"location":"about/#about","text":"The world of embedded systems is written almost entirely in C and C++. More and more of the embedded world move away from C and towards C++. This has to do with the many benefits of C++ such as type safety, compile time features, meta-programming, multi-paradigm and much more. When these features are used correctly, they can result in smaller binary sizes and higher performance code than in C. But a problem that embedded C++ software suffers is that there isn't a consistent and common API for embedded libraries. Looking around, you will find that each hardware vendor has their own set of libraries and tools for their specific products. If you write a driver on top of their libraries, you will find that your code will only work for that specific platform/product. In some cases you may also be limited to just their toolchain. You as the developer are locked in to this one specific setup. And if you move to another platform, you must do the work of rewriting all of your code again. libhal seeks to solve this issue by creating a set of generic interfaces for embedded system concepts such as serial communication (UART), analog to digital conversion (ADC), inertial measurement units (IMU), pulse width modulation (PWM) and much more. The advantage of building a system on top of libhal is that higher level drivers can be used with any target platform whether it is a stm32, a nxp micro controller, a RISC-V, or is on an embedded linux. This project is inspired by the work of Rust's embedded_hal and follows many of the same design goals. libhal's design goals: Serve as a foundation for building an ecosystem of platform agnostic drivers. Must abstract away device specific details like registers and bitmaps. Must be generic across devices such that any platform can be supported. Must be minimal for boosting performance and reducing size costs. Must be composable such that higher level drivers can build on top of these. Be accessible through package mangers so that developers can easily pick and choose which drivers they want to use.","title":"About"},{"location":"about/#software-copyrights","text":"This source code is licensed under the Apache License 2.0 as described in the LICENSE file.","title":"Software Copyrights"},{"location":"about/#third-party-library-licenses","text":"Boost.LEAF , BOOST license tl-function-ref/1.0.0 , CC0","title":"Third Party Library Licenses"},{"location":"architecture/","text":"\ud83c\udfd7\ufe0f Architectural Design Decisions A.1 Always use modern C++ libhal uses the modern C++. Meaning that libhal is will follow the most modern and available compilers available. When a sufficient number of features have become available in both GCC & Clang and are determined to be useful to libhal libhal will increment its major number to indicate that it has upgraded compiler versions. This decision exists to escape the issues of vendor and toolchain lock in thats prevalant in the C++ and embedded industry. With sufficient testing, upgrading compilers shouldn't result in bugs in applications. A.2 Interface Design Choices Interfaces MUST follow this layout: Use #pragma once at the start of the file: Simpler than an include guard All virtual functions must be private & each virtual functions is accompanied by a public API that is used to call the virtual API The return type of each API MUST be a result<T> where T is a structure. Pragma once is needed to ensure files are included once. Its also less error prone then hand writing include guards. The reasons for a private virtual with public API can be found in this article . Returning a structure for each API means that, in the future, if the return type needs to be extended, it can be done without breaking down stream libraries. For example: class adc { struct read_t { // V1 float percentage ; }; struct read_t { // V2 float percentage ; // Optional field that is default initialized to std::nullopt indicating // that it defaults to not exist std :: optional < uint8_t > bit_resolution = std :: nullopt ; }; }; Given that the field bit_resolution is an optional, code looking for it can determine if it is available or not, and code that never used it can ignore it. A.2.1 No utility methods in interfaces (UFCS) Utility functions shall not exist in interface definitions. For example, hal::i2c could have a hal::i2c::write() and hal::i2c::read() function implemented in its interface. This has the effect of reducing the number of headers in the interface files and dependencies. This, in turn, results in an interface that is minimal, clean, and simple. The major purpose of this is to keep compile times down as much possible for each interface. This also ensures that the \"pay-for-what-you-use\" model is followed. No need to pay for a utility you never planned to use. The final reason is in preparation for UFCS (Unified Function Call Syntax). UFCS is a proposal for C++23 and C++26. It did not get into C++23 but is slated for review in 26. For more details see this page What is unified function call syntax anyway? . A.3 Using tweak files over macros Tweak files were used as an alternative to MACROS. MACROs can be quite problematic in many situations and are advised against in the core C++ guidelines. The benefits of tweak files can be found here . A.4 Header Only Implementations libhal libraries and drivers are, in general, header-only. libhal uses header only implementations in order to enable the broadest set of package managers, build system and projects to use it. The strongest reason for a header-only approach is due to the fact that libhal libraries never intend to be distributed in prebuilt binaries. Conan is designed to ship with prebuilt binaries or build against the host machine. These settings can be altered, but you still end up with a single global prebuilt binary for a driver does not make sense when that driver could be used in a variety of environments such as the host device for host side tests, a specific target device, and a target device that is in the family of that specific target device. For example, lets consider liblpc40xx. If you are building to target the lpc4078 chip then that prebuilt ought to be built with usage of FPU registers enabled. But if you use that same prebuilt with the lpc4074, you'll find that the program crashes because the 74 variant does not have an FPU. You can attempt make a prebuilt binary for ever possible build variation that an embedded engineer may want, but you'll always come up short. The better approach is to simply build the library each time, thus ensuring that the build flags are considered each time. If compile-times are a concern, there are reasonably easy methods for managing this. See Handling Long Compile Times . A.5 Encapsulated Memory Mapped Classes Target drivers that use Memory-Mapped-IO usually come with a vendor generated header file that describes each peripheral as a structure type, along with bit mask MACROs, and MACROs that result in pointers to each peripheral in memory. The main problem using these headers files causes is naming conflicts. Many of these vendor generated headers work with both C and C++. Meaning that namespaces are not utilized. And many do not expect that they will be used in an environment where another vendor generated header file will exists. So no care is taken to ensure that the names of the types are unique. This WILL cause linker errors as the linker sees both GPIO_TypeDef from an STM library and GPIO_TypeDef from an LPC library that aren't the same. Because of this we have style S.x Encapsulated Memory Mapped classes guideline. A.6 Using hal::function_ref over std::function std::function has all of the flexibility and functionality needed, but it has the potential to allocate and requires potentially expensive copy operations when passed by value. hal::function_ref is a non-owning version of the std::function , with a size of just two pointers. hal::function_ref fits most use cases in that class functions that take them only need them for the duration of the function and do not need to own them for later. !!! info hal::function_ref is an alias for tl:function_ref which comes from the project TartanLlama/function_ref . A.7 Using virtual (runtime) polymorphism Polymorphism is critical for libhal to reach the goals of flexible and easy of use. Static based polymorphism, by its nature, is inflexible at runtime and can be quite complicated to work with. Runtime polymorphism, or the usage of virtual enables a broader scope of flexibility and isolation between drivers and application logic. The only downside to using virtual polymorphism is the cost of a virtual function call. But the actual cost of making a virtual function call is usually tiny in comparison to the work performed in the actual API call. In most cases the call latency and lack of inlining of a virtual call isn't an important factor in most applications. And over all, along with the broad amount of flexibility comes the ease of use. Virtual polymorphism for interfaces is very easy to perform and has a ton of language support. A.8 Strongly Leverage Package Managers Finding and integration libraries into C++ programs is a pain. Doing the same thing for embedded is doubly so, especially if there is vendor IDE lock in. libhal seeks to escape this by using the available package managers and indexes. Libhal was designed around and split up into parts that each come together via these package managers. The purpose of this design is to achieve: Stable version and release control for each library Can be easily found the indexes Ease of integration A.9 Foundation & Interface Stability libhal-util , libhal-mock and libhal-soft were all apart of libhal originally, but due to the constant changes and API breaks in those categories of code, the version number of libhal would increment constantly, shifting the foundation of the ecosystem. To prevent constant churn and API breaks libahl was split into those 4 libraries. The goal is to keep the version number for libhal constant for long periods of time to prevent breaking down stream libraries, drivers, and applications. A.10 libhal driver directory One of the libhal repos will contain a directory of libhal libraries that extend it along with which interfaces it implements and what type of library it is. Official libhal libraries must go into the directory. Developers outside of the libhal organization can also contribute to and opt into this directory by making a PR to the repo containing the directory. The purpose of this is to make finding and exploring the available set of drivers easier for the end developer by having them all in one place. A.11 Github Actions & Remote Workflows libhal uses github and github action \"workflow_dispatch\" to allow other repos to reuse libhal's continuous integration steps. The actions are configurable via input parameters to allow libraries to customize and control how the CI works. libhal's CI attempts to use as many tools as reasonable to make sure that the C++ source code follows the style guide, C++ core guidelines and retains a certain level of quality. All offical libhal libaries must opt in to the common libhal/libhal workflow. This helps to ensure that all projects are held to the same standard and quality. The workflow files can be found in libhal/libhal/.github/workflows . A.12 Boost.UT as our unit testing framework Boost.UT was chosen for its lack of macros, stunning compile time performance, and its ease of use. A.13 Boost.LEAF for error handling One major issue with any project is handling errors. Because the libhal interfaces can be used in such broad environments, it is hard to determine what the BEST error type in advance could work for all users. Some use error codes, some use std::expected<T, E> , and some use exceptions. Error codes are problematic as they tend to lack details and context around an error. Sometimes the documentation along with the error code provides all of the necessary context, but many times more context is needed. std::expected<T, E> seems like a better alternative to error codes, but... is it really? What should E be? An error code? What if we have it be an error code and a const string. What if we want a file name and function name? What about a line number? What about 16 bytes for holding context information about the error? That should be enough, right? What about- what about- what about? ... wait, how big is this error type? 32 bytes? Wasn't this supposed to be light weight? Unfortunately, std::expected is not a good choice for interfaces with extremely broad and unknowable of error states. This forces the error type to be massive to accommodate everything and everyone. Exceptions somewhat fix this issue but are still lacking. The benefit of exceptions is that you can throw just about anything, meaning the developer can provide loads of information in the thrown object. But exceptions fail on 4 counts: Exceptions tend to not be available for embedded systems, either due to a toolchain not compiling with them enabled or because a project has strict requirements that forbid exceptions. When exceptions do occur, the amount of time it takes to reach its catch can take a long time, longer than what real time applications can handle. Normally requires heap allocation Exceptions can only throw one type and the cost of those thrown exceptions are always paid for. Boost.LEAF has the following properties: Portable single-header format, no dependencies. Tiny code size when configured for embedded development. No dynamic memory allocations, even with very large payloads. Deterministic unbiased efficiency on the \"happy\" path and the \"sad\" path. Error objects are handled in constant time, independent of call stack depth. Can be used with or without exception handling. Can throw more than 1 error at a time All of these features are critical for libhal to have the performance for real time applications. The last feature is important for debugging, bug reports, and context specific error handling. Boost.LEAF gives the driver the choice to emit several error types and allows the user to pick out which one they would like to opt to catch if any of them. This can be used to capture an error code as well as s snapshot of the register map of a peripheral, the object's current state or even a debug message. A.14 Using Statement Expressions with HAL_CHECK() HAL_CHECK() is the only MACRO in libhal . It exists because there is nothing like Rust's ? operator which either unwraps a value or returns an error from the current function. The \"Statement Expression\" only works with GCC & Clang which is one of the reasons why libhal only supports those compilers. Compare the following two expressions: // 1. Using statement expressions auto percentage = HAL_CHECK ( adc . read ()). percentage ; // 2. Without using statement expressions HAL_CHECK ( adc_read_temporary , adc . read ()); auto percentage = adc_read_temporary . percentage ; The second option looks very unnatural and require explanation. On the other hand users who have never seen HAL_CHECK() in action have an immediate idea of how it works in the first section of the code. Portability to other compilers was sacrificed in order to make the code easier to read, understand, and write. A.15 libhal WILL NOT use fixed point Because fixed point will NOT result in better performance or space savings compared to SOFTWARE floating point. Team did venture to use fixed point throughout the entire code base and when we felt that the fixed point code reached a point where it was usable everywhere, we benchmarked it and got these: double_time = 8921794 [i64 +Round]fixed_time = 4558238 (best fixed point option) [soft]float_time = 1424913 [i64 -Round]fixed_time = 1410720 (precision issues) [i32 +Round]fixed_time = 815107 (will easily overflow) [hard]float_time = 110089 (not always available) [i32 -Round]fixed_time = 95085 (will not actually work) Here is an old gist of the example: kammce/fixed_v_float.cpp The above metrics were for a program that run a map function to map an input number from one range to another range. The numbers on the right hand side are the number of cycles of a Arm Cortex M4F DWT counter. Fixed point 32-bit integers is enough for a representation but to handle arithmetic like multiplication, 64-bit integers were needed. Those 64-bit operations resulted in computation time approaching double floating point. If a system used 32-bit floats, the 32-bit fixed point would be ~4x slower. If a system used double floating point in software mode, it will only be ~2x slower than 32-bit fixed point. Fixed point, over all, is more expensive in terms of space and time. If you don't believe the metrics measured here, you can also check fpm performance metrics . Notice how fpm fairs far worse for anything that isn't addition/subtraction. See these articles for more details: You're Going To Have To Think! WHY FIXED POINT WON'T CURE YOUR FLOATING POINT BLUES WHY RATIONALS WON\u2019T CURE YOUR FLOATING POINT BLUES Why Computer Algebra Won\u2019t Cure Your Floating Point Blues Why Interval Arithmetic Won\u2019t Cure Your Floating Point Blues A.16 libhal does NOT use a units library Unit libraries have the potential to really help prevent an entire category of unit based errors, it is also extremely difficult and annoying to use. Th article Unit of measurement libraries, their popularity and suitability goes into detail about the usability issues faced by unit libraries. Because, at the time of writing libhal there is not a unit library that is easy to use and concise, libhal decided to simply stick with 32-bit floats and helper UDLs. A.17 Always return hal::result<T> from every API Every interface in libhal returns a hal::result<T> type. The return types should be a result<T> because the implementation could be an abstraction for anything. As an example, it could come from an I2C to PWM generator and if something goes wrong with the i2c communication, the information must be emitted from the function. A.18 Using inplace_function / hal::callback for interrupt callbacks There are interfaces such as hal::can , hal::interrupt_pin , and hal::timer that all have APIs for setting a callback. Because those callbacks could be lambdas, function objects, pure functions, or other callable types, we need a polymorphic type erased function type that can take any callable type as input and call it when its operator() is called. The options for these callbacks are: std::function PROS Part of the standard library Can take any callable type without restrictions CONS Allocating (compiler implementations will use SBO but the size of those buffers are not specified in the standard and should not be relied upon) Can be quite large in size (40 bytes on 32-bit arm) function_ref PROS Very lightweight (very fast construction) Very small size (2 pointers in size) CONS For this to work as a callback, the callable passed to the function_ref must have a lifetime that is greater than the object implementing the interface. inplace_function PROS Works and behaves just like std::function CONS Fixed callable size limit std::function is automatically out because it is allocating. Using std::function for any interface API would ensure that applications that disallow dynamic allocations after boot or in general could never use them. function_ref has two great PROS but the largets CON is lifetime issues that are really easy to fall into. Specifically something like this: obj . on_event ([ & single_capture ]() { // does a thing ... }); The lambda is actually a temporary! So after this call it is out of scope and no longer exists. If the reference to temporary is stored and called later, the code WILL suffer from a \"stack use after scope\" violation which is undefined behavior. inplace_function has all of the features of std::function but with limited size. Due to this, constructing an inplace_function is deterministic and relatively light weight. A.19 hal::callback sizing hal::callback is an alias to inplace_function with a buffer size of 2 pointers ( sizeof(std::intptr_t) * 2 ). This size was chosen in order to be small and easily storable. Two pointers worth of size should be enough to hold a pointer to this in classes as well a pointer to some sort of state object. The size of the callback object was not choosen in order to improve the performance of calling callback setting class functions. Even with the small size of hal::callback , its too large to take advantage of register based parameter passing. Thus the size of 2 pointers was mostly to help in keeping the memory footprint of the callback small. In most cases, setting an callback is something that is either done once or done very infrequently, and thus does not get much of a benefit from higher performance function calls. A.20 Why functions that setup events do not return hal::status Functions like hal::can::on_receive() and hal::interrupt_pin::on_trigger() return void and not hal::status like other APIs. Thus these functions cannot return an error and are considered \"infallible\". There infallibility guarantee makes constructing drivers using these interfaces easier. It also eliminates the need for drivers to concern themselves with handling errors from these APIs. This guarantee is easily made, because having any one of these APIs fail IS A bug and not something that a developer should or could be responsible with handling. These APIs MUST be implemented as target library peripheral drivers because setting interrupts is something that only target and processor libraries can do. Setting up and configuring interrupts is only possible if the processor supports it. Being apart of a target library means that they know exactly the set of possible configurations that are allowed. This also means that constructing a target peripheral with interrupt customization can be include compile time checks as well.","title":"\ud83c\udfd7\ufe0f Architectural Design Decisions"},{"location":"architecture/#architectural-design-decisions","text":"","title":"\ud83c\udfd7\ufe0f Architectural Design Decisions"},{"location":"architecture/#a1-always-use-modern-c","text":"libhal uses the modern C++. Meaning that libhal is will follow the most modern and available compilers available. When a sufficient number of features have become available in both GCC & Clang and are determined to be useful to libhal libhal will increment its major number to indicate that it has upgraded compiler versions. This decision exists to escape the issues of vendor and toolchain lock in thats prevalant in the C++ and embedded industry. With sufficient testing, upgrading compilers shouldn't result in bugs in applications.","title":"A.1 Always use modern C++"},{"location":"architecture/#a2-interface-design-choices","text":"Interfaces MUST follow this layout: Use #pragma once at the start of the file: Simpler than an include guard All virtual functions must be private & each virtual functions is accompanied by a public API that is used to call the virtual API The return type of each API MUST be a result<T> where T is a structure. Pragma once is needed to ensure files are included once. Its also less error prone then hand writing include guards. The reasons for a private virtual with public API can be found in this article . Returning a structure for each API means that, in the future, if the return type needs to be extended, it can be done without breaking down stream libraries. For example: class adc { struct read_t { // V1 float percentage ; }; struct read_t { // V2 float percentage ; // Optional field that is default initialized to std::nullopt indicating // that it defaults to not exist std :: optional < uint8_t > bit_resolution = std :: nullopt ; }; }; Given that the field bit_resolution is an optional, code looking for it can determine if it is available or not, and code that never used it can ignore it.","title":"A.2 Interface Design Choices"},{"location":"architecture/#a21-no-utility-methods-in-interfaces-ufcs","text":"Utility functions shall not exist in interface definitions. For example, hal::i2c could have a hal::i2c::write() and hal::i2c::read() function implemented in its interface. This has the effect of reducing the number of headers in the interface files and dependencies. This, in turn, results in an interface that is minimal, clean, and simple. The major purpose of this is to keep compile times down as much possible for each interface. This also ensures that the \"pay-for-what-you-use\" model is followed. No need to pay for a utility you never planned to use. The final reason is in preparation for UFCS (Unified Function Call Syntax). UFCS is a proposal for C++23 and C++26. It did not get into C++23 but is slated for review in 26. For more details see this page What is unified function call syntax anyway? .","title":"A.2.1 No utility methods in interfaces (UFCS)"},{"location":"architecture/#a3-using-tweak-files-over-macros","text":"Tweak files were used as an alternative to MACROS. MACROs can be quite problematic in many situations and are advised against in the core C++ guidelines. The benefits of tweak files can be found here .","title":"A.3 Using tweak files over macros"},{"location":"architecture/#a4-header-only-implementations","text":"libhal libraries and drivers are, in general, header-only. libhal uses header only implementations in order to enable the broadest set of package managers, build system and projects to use it. The strongest reason for a header-only approach is due to the fact that libhal libraries never intend to be distributed in prebuilt binaries. Conan is designed to ship with prebuilt binaries or build against the host machine. These settings can be altered, but you still end up with a single global prebuilt binary for a driver does not make sense when that driver could be used in a variety of environments such as the host device for host side tests, a specific target device, and a target device that is in the family of that specific target device. For example, lets consider liblpc40xx. If you are building to target the lpc4078 chip then that prebuilt ought to be built with usage of FPU registers enabled. But if you use that same prebuilt with the lpc4074, you'll find that the program crashes because the 74 variant does not have an FPU. You can attempt make a prebuilt binary for ever possible build variation that an embedded engineer may want, but you'll always come up short. The better approach is to simply build the library each time, thus ensuring that the build flags are considered each time. If compile-times are a concern, there are reasonably easy methods for managing this. See Handling Long Compile Times .","title":"A.4 Header Only Implementations"},{"location":"architecture/#a5-encapsulated-memory-mapped-classes","text":"Target drivers that use Memory-Mapped-IO usually come with a vendor generated header file that describes each peripheral as a structure type, along with bit mask MACROs, and MACROs that result in pointers to each peripheral in memory. The main problem using these headers files causes is naming conflicts. Many of these vendor generated headers work with both C and C++. Meaning that namespaces are not utilized. And many do not expect that they will be used in an environment where another vendor generated header file will exists. So no care is taken to ensure that the names of the types are unique. This WILL cause linker errors as the linker sees both GPIO_TypeDef from an STM library and GPIO_TypeDef from an LPC library that aren't the same. Because of this we have style S.x Encapsulated Memory Mapped classes guideline.","title":"A.5 Encapsulated Memory Mapped Classes"},{"location":"architecture/#a6-using-halfunction_ref-over-stdfunction","text":"std::function has all of the flexibility and functionality needed, but it has the potential to allocate and requires potentially expensive copy operations when passed by value. hal::function_ref is a non-owning version of the std::function , with a size of just two pointers. hal::function_ref fits most use cases in that class functions that take them only need them for the duration of the function and do not need to own them for later. !!! info hal::function_ref is an alias for tl:function_ref which comes from the project TartanLlama/function_ref .","title":"A.6 Using hal::function_ref over std::function"},{"location":"architecture/#a7-using-virtual-runtime-polymorphism","text":"Polymorphism is critical for libhal to reach the goals of flexible and easy of use. Static based polymorphism, by its nature, is inflexible at runtime and can be quite complicated to work with. Runtime polymorphism, or the usage of virtual enables a broader scope of flexibility and isolation between drivers and application logic. The only downside to using virtual polymorphism is the cost of a virtual function call. But the actual cost of making a virtual function call is usually tiny in comparison to the work performed in the actual API call. In most cases the call latency and lack of inlining of a virtual call isn't an important factor in most applications. And over all, along with the broad amount of flexibility comes the ease of use. Virtual polymorphism for interfaces is very easy to perform and has a ton of language support.","title":"A.7 Using virtual (runtime) polymorphism"},{"location":"architecture/#a8-strongly-leverage-package-managers","text":"Finding and integration libraries into C++ programs is a pain. Doing the same thing for embedded is doubly so, especially if there is vendor IDE lock in. libhal seeks to escape this by using the available package managers and indexes. Libhal was designed around and split up into parts that each come together via these package managers. The purpose of this design is to achieve: Stable version and release control for each library Can be easily found the indexes Ease of integration","title":"A.8 Strongly Leverage Package Managers"},{"location":"architecture/#a9-foundation-interface-stability","text":"libhal-util , libhal-mock and libhal-soft were all apart of libhal originally, but due to the constant changes and API breaks in those categories of code, the version number of libhal would increment constantly, shifting the foundation of the ecosystem. To prevent constant churn and API breaks libahl was split into those 4 libraries. The goal is to keep the version number for libhal constant for long periods of time to prevent breaking down stream libraries, drivers, and applications.","title":"A.9 Foundation &amp; Interface Stability"},{"location":"architecture/#a10-libhal-driver-directory","text":"One of the libhal repos will contain a directory of libhal libraries that extend it along with which interfaces it implements and what type of library it is. Official libhal libraries must go into the directory. Developers outside of the libhal organization can also contribute to and opt into this directory by making a PR to the repo containing the directory. The purpose of this is to make finding and exploring the available set of drivers easier for the end developer by having them all in one place.","title":"A.10 libhal driver directory"},{"location":"architecture/#a11-github-actions-remote-workflows","text":"libhal uses github and github action \"workflow_dispatch\" to allow other repos to reuse libhal's continuous integration steps. The actions are configurable via input parameters to allow libraries to customize and control how the CI works. libhal's CI attempts to use as many tools as reasonable to make sure that the C++ source code follows the style guide, C++ core guidelines and retains a certain level of quality. All offical libhal libaries must opt in to the common libhal/libhal workflow. This helps to ensure that all projects are held to the same standard and quality. The workflow files can be found in libhal/libhal/.github/workflows .","title":"A.11 Github Actions &amp; Remote Workflows"},{"location":"architecture/#a12-boostut-as-our-unit-testing-framework","text":"Boost.UT was chosen for its lack of macros, stunning compile time performance, and its ease of use.","title":"A.12 Boost.UT as our unit testing framework"},{"location":"architecture/#a13-boostleaf-for-error-handling","text":"One major issue with any project is handling errors. Because the libhal interfaces can be used in such broad environments, it is hard to determine what the BEST error type in advance could work for all users. Some use error codes, some use std::expected<T, E> , and some use exceptions. Error codes are problematic as they tend to lack details and context around an error. Sometimes the documentation along with the error code provides all of the necessary context, but many times more context is needed. std::expected<T, E> seems like a better alternative to error codes, but... is it really? What should E be? An error code? What if we have it be an error code and a const string. What if we want a file name and function name? What about a line number? What about 16 bytes for holding context information about the error? That should be enough, right? What about- what about- what about? ... wait, how big is this error type? 32 bytes? Wasn't this supposed to be light weight? Unfortunately, std::expected is not a good choice for interfaces with extremely broad and unknowable of error states. This forces the error type to be massive to accommodate everything and everyone. Exceptions somewhat fix this issue but are still lacking. The benefit of exceptions is that you can throw just about anything, meaning the developer can provide loads of information in the thrown object. But exceptions fail on 4 counts: Exceptions tend to not be available for embedded systems, either due to a toolchain not compiling with them enabled or because a project has strict requirements that forbid exceptions. When exceptions do occur, the amount of time it takes to reach its catch can take a long time, longer than what real time applications can handle. Normally requires heap allocation Exceptions can only throw one type and the cost of those thrown exceptions are always paid for. Boost.LEAF has the following properties: Portable single-header format, no dependencies. Tiny code size when configured for embedded development. No dynamic memory allocations, even with very large payloads. Deterministic unbiased efficiency on the \"happy\" path and the \"sad\" path. Error objects are handled in constant time, independent of call stack depth. Can be used with or without exception handling. Can throw more than 1 error at a time All of these features are critical for libhal to have the performance for real time applications. The last feature is important for debugging, bug reports, and context specific error handling. Boost.LEAF gives the driver the choice to emit several error types and allows the user to pick out which one they would like to opt to catch if any of them. This can be used to capture an error code as well as s snapshot of the register map of a peripheral, the object's current state or even a debug message.","title":"A.13 Boost.LEAF for error handling"},{"location":"architecture/#a14-using-statement-expressions-with-hal_check","text":"HAL_CHECK() is the only MACRO in libhal . It exists because there is nothing like Rust's ? operator which either unwraps a value or returns an error from the current function. The \"Statement Expression\" only works with GCC & Clang which is one of the reasons why libhal only supports those compilers. Compare the following two expressions: // 1. Using statement expressions auto percentage = HAL_CHECK ( adc . read ()). percentage ; // 2. Without using statement expressions HAL_CHECK ( adc_read_temporary , adc . read ()); auto percentage = adc_read_temporary . percentage ; The second option looks very unnatural and require explanation. On the other hand users who have never seen HAL_CHECK() in action have an immediate idea of how it works in the first section of the code. Portability to other compilers was sacrificed in order to make the code easier to read, understand, and write.","title":"A.14 Using Statement Expressions with HAL_CHECK()"},{"location":"architecture/#a15-libhal-will-not-use-fixed-point","text":"Because fixed point will NOT result in better performance or space savings compared to SOFTWARE floating point. Team did venture to use fixed point throughout the entire code base and when we felt that the fixed point code reached a point where it was usable everywhere, we benchmarked it and got these: double_time = 8921794 [i64 +Round]fixed_time = 4558238 (best fixed point option) [soft]float_time = 1424913 [i64 -Round]fixed_time = 1410720 (precision issues) [i32 +Round]fixed_time = 815107 (will easily overflow) [hard]float_time = 110089 (not always available) [i32 -Round]fixed_time = 95085 (will not actually work) Here is an old gist of the example: kammce/fixed_v_float.cpp The above metrics were for a program that run a map function to map an input number from one range to another range. The numbers on the right hand side are the number of cycles of a Arm Cortex M4F DWT counter. Fixed point 32-bit integers is enough for a representation but to handle arithmetic like multiplication, 64-bit integers were needed. Those 64-bit operations resulted in computation time approaching double floating point. If a system used 32-bit floats, the 32-bit fixed point would be ~4x slower. If a system used double floating point in software mode, it will only be ~2x slower than 32-bit fixed point. Fixed point, over all, is more expensive in terms of space and time. If you don't believe the metrics measured here, you can also check fpm performance metrics . Notice how fpm fairs far worse for anything that isn't addition/subtraction. See these articles for more details: You're Going To Have To Think! WHY FIXED POINT WON'T CURE YOUR FLOATING POINT BLUES WHY RATIONALS WON\u2019T CURE YOUR FLOATING POINT BLUES Why Computer Algebra Won\u2019t Cure Your Floating Point Blues Why Interval Arithmetic Won\u2019t Cure Your Floating Point Blues","title":"A.15 libhal WILL NOT use fixed point"},{"location":"architecture/#a16-libhal-does-not-use-a-units-library","text":"Unit libraries have the potential to really help prevent an entire category of unit based errors, it is also extremely difficult and annoying to use. Th article Unit of measurement libraries, their popularity and suitability goes into detail about the usability issues faced by unit libraries. Because, at the time of writing libhal there is not a unit library that is easy to use and concise, libhal decided to simply stick with 32-bit floats and helper UDLs.","title":"A.16 libhal does NOT use a units library"},{"location":"architecture/#a17-always-return-halresultt-from-every-api","text":"Every interface in libhal returns a hal::result<T> type. The return types should be a result<T> because the implementation could be an abstraction for anything. As an example, it could come from an I2C to PWM generator and if something goes wrong with the i2c communication, the information must be emitted from the function.","title":"A.17 Always return hal::result&lt;T&gt; from every API"},{"location":"architecture/#a18-using-inplace_functionhalcallback-for-interrupt-callbacks","text":"There are interfaces such as hal::can , hal::interrupt_pin , and hal::timer that all have APIs for setting a callback. Because those callbacks could be lambdas, function objects, pure functions, or other callable types, we need a polymorphic type erased function type that can take any callable type as input and call it when its operator() is called. The options for these callbacks are: std::function PROS Part of the standard library Can take any callable type without restrictions CONS Allocating (compiler implementations will use SBO but the size of those buffers are not specified in the standard and should not be relied upon) Can be quite large in size (40 bytes on 32-bit arm) function_ref PROS Very lightweight (very fast construction) Very small size (2 pointers in size) CONS For this to work as a callback, the callable passed to the function_ref must have a lifetime that is greater than the object implementing the interface. inplace_function PROS Works and behaves just like std::function CONS Fixed callable size limit std::function is automatically out because it is allocating. Using std::function for any interface API would ensure that applications that disallow dynamic allocations after boot or in general could never use them. function_ref has two great PROS but the largets CON is lifetime issues that are really easy to fall into. Specifically something like this: obj . on_event ([ & single_capture ]() { // does a thing ... }); The lambda is actually a temporary! So after this call it is out of scope and no longer exists. If the reference to temporary is stored and called later, the code WILL suffer from a \"stack use after scope\" violation which is undefined behavior. inplace_function has all of the features of std::function but with limited size. Due to this, constructing an inplace_function is deterministic and relatively light weight.","title":"A.18 Using inplace_function/hal::callback for interrupt callbacks"},{"location":"architecture/#a19-halcallback-sizing","text":"hal::callback is an alias to inplace_function with a buffer size of 2 pointers ( sizeof(std::intptr_t) * 2 ). This size was chosen in order to be small and easily storable. Two pointers worth of size should be enough to hold a pointer to this in classes as well a pointer to some sort of state object. The size of the callback object was not choosen in order to improve the performance of calling callback setting class functions. Even with the small size of hal::callback , its too large to take advantage of register based parameter passing. Thus the size of 2 pointers was mostly to help in keeping the memory footprint of the callback small. In most cases, setting an callback is something that is either done once or done very infrequently, and thus does not get much of a benefit from higher performance function calls.","title":"A.19 hal::callback sizing"},{"location":"architecture/#a20-why-functions-that-setup-events-do-not-return-halstatus","text":"Functions like hal::can::on_receive() and hal::interrupt_pin::on_trigger() return void and not hal::status like other APIs. Thus these functions cannot return an error and are considered \"infallible\". There infallibility guarantee makes constructing drivers using these interfaces easier. It also eliminates the need for drivers to concern themselves with handling errors from these APIs. This guarantee is easily made, because having any one of these APIs fail IS A bug and not something that a developer should or could be responsible with handling. These APIs MUST be implemented as target library peripheral drivers because setting interrupts is something that only target and processor libraries can do. Setting up and configuring interrupts is only possible if the processor supports it. Being apart of a target library means that they know exactly the set of possible configurations that are allowed. This also means that constructing a target peripheral with interrupt customization can be include compile time checks as well.","title":"A.20 Why functions that setup events do not return hal::status"},{"location":"glossary/","text":"\ud83d\udcc3 Learning the Terms Here is a list of terms used in libhal. It is HIGHLY RECOMMENDED that new users of libhal read this section. Target(s) Targets are defined as MCUs (micro-controllers), SOCs (system-on-chip), operating systems, or operating systems running on a particular SBC (single-board-computer). The following are examples: MCU AP OS SOC LPC40xx series family of MCUs STM32F10x series family of MCUs RP2040 Broadcom BCM2836 SoC (Raspberry Pi) Samsung Exynos5422 (Odroid) TI AM335x Sitara Linux Windows CE Raspberry Pi ODROID UX BeagleBone Black Interface(s) Interfaces are the basic building blocks of libhal and enable the flexibility needed to be portable and flexible. An interface is a contract of functions that an implementing class must adhere to. Documentation for each interface API explain the expected behavior that each function should have on hardware regardless of the implementation. Any software that implements (inherits) an interface must provide implementations for each function in the interface, otherwise the compiler will generate a compiler error. In libhal each interface corresponds to a type of hardware peripheral or device such as: hal::output_pin & hal::input_pin : Digital I/O (input/output pins) hal::adc : Analog to digital converter hal::pwm : Pulse width modulation (pwm) hal::spi : Serial peripheral interface (spi) hal::serial : Universal asynchronous receiver transmitter (serial/uart) hal::accelerometer : Accelerometer Driver Types Peripheral Device Soft Peripheral drivers are drivers for a target that is embedded within the device and therefore cannot be removed from the chip and is fixed in number. Example: A digital output and input pin Example: 1 of 5 hardware timers within a micro-controller Example: Integrated analog-to-digital converter Device drivers are drivers for devices external to a target. In order to communicate with such a device the target must have the necessary peripherals and peripheral drivers to operate correctly. Example: an accelerometer driver for the mpu6050 Example: a memory storage driver for a at581 flash memory Example: a black and white pixel display Soft drivers are drivers that do not have any specific underlying hardware associated with them. They are used to emulate, give context to, or alter the behavior of interfaces. For a driver to be a soft driver it must implement or have a way to generate, construct or create implementations of hardware interfaces. Emulation Example Emulate spi by using 2 output pins and 1 input pin. Emulate uart transmission with a 16-bit spi driver and some clever bit positioning. Context Example Implement a rotary encoder by using an adc, a potentiometer and some specification of the potentiometer like min and max angle, along with min and max voltage. Implement a dac using multiple output pins and a set of resistors and an op amp. Alteration example Implement an input pin that inverts the readings of an actual input pin Implement an i2c driver that is thread safe by taking an i2c and locking mechanism provided by the user. In general, software drivers tend to incur some overhead so nesting them deeply will effect performance. Processes A process is code that performs some work. Like an application on a desktop machine. Off Interface Function Off Interface functions are public class functions that a driver can have that is beyond what is available for the interface it is implementing. These functions usually configure a peripheral or device in a way that is outside the scope of the implementing interface. For peripherals these are platform specific. For drivers these are device specific features. Examples of such specific functions are as follows: An output pin driver with a high drain current mode An input pin driver with support for inverting the voltage level of what it reads in hardware. Enabling/disabling continuous sampling from an accelerometer where sampling continuously would make reading samples faster but would consume more power and disabling continuous sampling would do the opposite. Types of Libraries target utility device application Target libraries contain the driver implementations for specific targets. Every application that uses libhal will need one of these libraries in order to work on any hardware. Without such libraries, the device could run an application, but couldn't interact with the world. Utility libraries are purely software libraries that help to either make performing some work on a device easier for the developer or help to organize and bring structure to an application. Device libraries are libraries containing drivers for specific hardware devices or module, such as a sensor, display or a motor controller. They are, generally, target agnostic and should be usable on any system that can support its interface, memory, and performance requirements. An application library is a full application that can be used as part of another application library or project.","title":"\ud83d\udcc3 Learning the Terms"},{"location":"glossary/#learning-the-terms","text":"Here is a list of terms used in libhal. It is HIGHLY RECOMMENDED that new users of libhal read this section.","title":"\ud83d\udcc3 Learning the Terms"},{"location":"glossary/#targets","text":"Targets are defined as MCUs (micro-controllers), SOCs (system-on-chip), operating systems, or operating systems running on a particular SBC (single-board-computer). The following are examples: MCU AP OS SOC LPC40xx series family of MCUs STM32F10x series family of MCUs RP2040 Broadcom BCM2836 SoC (Raspberry Pi) Samsung Exynos5422 (Odroid) TI AM335x Sitara Linux Windows CE Raspberry Pi ODROID UX BeagleBone Black","title":"Target(s)"},{"location":"glossary/#interfaces","text":"Interfaces are the basic building blocks of libhal and enable the flexibility needed to be portable and flexible. An interface is a contract of functions that an implementing class must adhere to. Documentation for each interface API explain the expected behavior that each function should have on hardware regardless of the implementation. Any software that implements (inherits) an interface must provide implementations for each function in the interface, otherwise the compiler will generate a compiler error. In libhal each interface corresponds to a type of hardware peripheral or device such as: hal::output_pin & hal::input_pin : Digital I/O (input/output pins) hal::adc : Analog to digital converter hal::pwm : Pulse width modulation (pwm) hal::spi : Serial peripheral interface (spi) hal::serial : Universal asynchronous receiver transmitter (serial/uart) hal::accelerometer : Accelerometer","title":"Interface(s)"},{"location":"glossary/#driver-types","text":"Peripheral Device Soft Peripheral drivers are drivers for a target that is embedded within the device and therefore cannot be removed from the chip and is fixed in number. Example: A digital output and input pin Example: 1 of 5 hardware timers within a micro-controller Example: Integrated analog-to-digital converter Device drivers are drivers for devices external to a target. In order to communicate with such a device the target must have the necessary peripherals and peripheral drivers to operate correctly. Example: an accelerometer driver for the mpu6050 Example: a memory storage driver for a at581 flash memory Example: a black and white pixel display Soft drivers are drivers that do not have any specific underlying hardware associated with them. They are used to emulate, give context to, or alter the behavior of interfaces. For a driver to be a soft driver it must implement or have a way to generate, construct or create implementations of hardware interfaces. Emulation Example Emulate spi by using 2 output pins and 1 input pin. Emulate uart transmission with a 16-bit spi driver and some clever bit positioning. Context Example Implement a rotary encoder by using an adc, a potentiometer and some specification of the potentiometer like min and max angle, along with min and max voltage. Implement a dac using multiple output pins and a set of resistors and an op amp. Alteration example Implement an input pin that inverts the readings of an actual input pin Implement an i2c driver that is thread safe by taking an i2c and locking mechanism provided by the user. In general, software drivers tend to incur some overhead so nesting them deeply will effect performance.","title":"Driver Types"},{"location":"glossary/#processes","text":"A process is code that performs some work. Like an application on a desktop machine.","title":"Processes"},{"location":"glossary/#off-interface-function","text":"Off Interface functions are public class functions that a driver can have that is beyond what is available for the interface it is implementing. These functions usually configure a peripheral or device in a way that is outside the scope of the implementing interface. For peripherals these are platform specific. For drivers these are device specific features. Examples of such specific functions are as follows: An output pin driver with a high drain current mode An input pin driver with support for inverting the voltage level of what it reads in hardware. Enabling/disabling continuous sampling from an accelerometer where sampling continuously would make reading samples faster but would consume more power and disabling continuous sampling would do the opposite.","title":"Off Interface Function"},{"location":"glossary/#types-of-libraries","text":"target utility device application Target libraries contain the driver implementations for specific targets. Every application that uses libhal will need one of these libraries in order to work on any hardware. Without such libraries, the device could run an application, but couldn't interact with the world. Utility libraries are purely software libraries that help to either make performing some work on a device easier for the developer or help to organize and bring structure to an application. Device libraries are libraries containing drivers for specific hardware devices or module, such as a sensor, display or a motor controller. They are, generally, target agnostic and should be usable on any system that can support its interface, memory, and performance requirements. An application library is a full application that can be used as part of another application library or project.","title":"Types of Libraries"},{"location":"philosophy/","text":"\ud83d\udcdc Design Philosophy These are the core design tenets that libhal and libraries extending it must seek to achieve with every design choice, line written, and architecture change made. D.1 Multi Targeted libhal and the libraries that extend it, should work anywhere. So long as the appropriate compiler or cross compiler is used, the driver should do as it is intended. The exception is target libraries which are designated to execute for a particular target. Even so, those target libraries MUST be unit testable on any host machine. D.2 Light Weight libhal should keep its interfaces and utility code light weight, meaning such things do not allocate, and if they do only once, do not perform long/length copies, unless a copy was the desired operation, D.3 General libhal interfaces should be general, meaning that they do not include APIs, or configuration settings that are uncommon in most targets or specific to a particular target. D.4 Minimalist libhal aims to be as simple as possible and no simpler. Interfaces, utility functions, and libraries should be straight forward for most programmers to understand with added complexity only when it is necessary and no other options exist. D.5 Safe libhal and its style guide aim to use patterns and techniques that help reduce safety issues. Safety does NOT extend to runtime checks that determine if there exists architectural defects. D.6 Tested & Testable libhal code should be as testable and unit tested. D.7 Compiled Quickly libhal code should build fast and eliminate/replace any unnecessary dependencies that cause compile times to be long. D.8 Portable libhal code should not require or depend on any OS or target specific code or behaviors. libhal is designed to work anywhere and should not rely on OS.","title":"\ud83d\udcdc Design Philosophy"},{"location":"philosophy/#design-philosophy","text":"These are the core design tenets that libhal and libraries extending it must seek to achieve with every design choice, line written, and architecture change made.","title":"\ud83d\udcdc Design Philosophy"},{"location":"philosophy/#d1-multi-targeted","text":"libhal and the libraries that extend it, should work anywhere. So long as the appropriate compiler or cross compiler is used, the driver should do as it is intended. The exception is target libraries which are designated to execute for a particular target. Even so, those target libraries MUST be unit testable on any host machine.","title":"D.1 Multi Targeted"},{"location":"philosophy/#d2-light-weight","text":"libhal should keep its interfaces and utility code light weight, meaning such things do not allocate, and if they do only once, do not perform long/length copies, unless a copy was the desired operation,","title":"D.2 Light Weight"},{"location":"philosophy/#d3-general","text":"libhal interfaces should be general, meaning that they do not include APIs, or configuration settings that are uncommon in most targets or specific to a particular target.","title":"D.3 General"},{"location":"philosophy/#d4-minimalist","text":"libhal aims to be as simple as possible and no simpler. Interfaces, utility functions, and libraries should be straight forward for most programmers to understand with added complexity only when it is necessary and no other options exist.","title":"D.4 Minimalist"},{"location":"philosophy/#d5-safe","text":"libhal and its style guide aim to use patterns and techniques that help reduce safety issues. Safety does NOT extend to runtime checks that determine if there exists architectural defects.","title":"D.5 Safe"},{"location":"philosophy/#d6-tested-testable","text":"libhal code should be as testable and unit tested.","title":"D.6 Tested &amp; Testable"},{"location":"philosophy/#d7-compiled-quickly","text":"libhal code should build fast and eliminate/replace any unnecessary dependencies that cause compile times to be long.","title":"D.7 Compiled Quickly"},{"location":"philosophy/#d8-portable","text":"libhal code should not require or depend on any OS or target specific code or behaviors. libhal is designed to work anywhere and should not rely on OS.","title":"D.8 Portable"},{"location":"prerequisites/","text":"\ud83e\uddf0 Install Prerequisites What you will need in order to get started with libhal. make : latest available version cmake : 3.15 or above python : 3.10 or above conan : 1.57.0 Suitable Compiler for running host tests (can be either of these): gcc : 11.3.0 or above clang : 14 and above Ubuntu 22.04 Ubuntu 20.04 MacOS X Windows Python 3.10 is default installed, no need to install it. Install GCC and build essentials: sudo apt update && sudo apt upgrade sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test sudo apt install -y build-essential g++-11 Installing conan & cmake: python3 -m pip install conan cmake Install python3.9: sudo apt-get install python3.9 Install GCC and build essentials: sudo apt update && sudo apt upgrade sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test sudo apt install -y build-essential g++-11 Installing conan & cmake: python3.9 -m pip install conan cmake Install Homebrew: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Install latest version of Python 3.x: brew install python Install conan & cmake: python3 -m pip install conan cmake Install Rosetta (only required for M1 macs): /usr/sbin/softwareupdate --install-rosetta --agree-to-license Rosetta necessary for intel based cross compilers: We recommend using the choco package manager for windows as it allows easy installation of tools via the command line. To install choco , open PowerShell as an administrator and run the following command: Set-ExecutionPolicy Bypass -Scope Process -Force ; [System.Net.ServicePointManager] :: SecurityProtocol = [System.Net.ServicePointManager] :: SecurityProtocol -bor 3072 ; iex (( New-Object System . Net . WebClient ). DownloadString ( 'https://community.chocolatey.org/install.ps1' )) Tip If the choco command doesn't work after running this script try closing and opening again PowerShell. Now install python : choco install python Install gcc via the mingw : choco install mingw Install make for cmake: choco install make Installing conan & cmake: python3 -m pip install -U conan cmake Setting up Conan First lets create a default profile: conan profile detect --force Add libhal-trunk repository to conan remotes This allows conan to search for packages in the libhal-trunk repository, which is updated with every change to the libhal organizations code base. conan remote add libhal-trunk https://libhal.jfrog.io/artifactory/api/conan/trunk-conan Profile setting for GCC 11 users Intel Linux ARM64 Linux M1 Mac Intel Mac Intel Windows ARM64 Windows If your host machine is using an intel core processor as its CPU then you'll want to use this default configuration. conan config install -sf profiles/x86_64/linux/ -tf profiles https://github.com/libhal/conan-config.git It is less likely your host desktop is an ARM64. This section is mostly for building applications and tests on a Raspberry PI or other SBC. But if you do have a laptop powered by an ARM64 core, then this is the correct configuration for you. conan config install -sf profiles/armv8/linux/ -tf profiles https://github.com/libhal/conan-config.git If your macbook uses an M1 processor then you'll want to use this default configuration. conan config install -sf profiles/armv8/mac/ -tf profiles https://github.com/libhal/conan-config.git If your macbook uses an Intel processor then you'll want to use this default configuration. conan config install -sf profiles/x86_64/mac/ -tf profiles https://github.com/libhal/conan-config.git If your windows machine uses an Intel processor then you'll want to use this default configuration. conan config install -sf profiles/x86_64/windows/ -tf profiles https://github.com/libhal/conan-config.git If you have a modern surface laptop with ARM64, then this may be the right choice for you. conan config install -sf profiles/armv8/windows/ -tf profiles https://github.com/libhal/conan-config.git","title":"\ud83e\uddf0 Install Prerequisites"},{"location":"prerequisites/#install-prerequisites","text":"What you will need in order to get started with libhal. make : latest available version cmake : 3.15 or above python : 3.10 or above conan : 1.57.0 Suitable Compiler for running host tests (can be either of these): gcc : 11.3.0 or above clang : 14 and above Ubuntu 22.04 Ubuntu 20.04 MacOS X Windows Python 3.10 is default installed, no need to install it. Install GCC and build essentials: sudo apt update && sudo apt upgrade sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test sudo apt install -y build-essential g++-11 Installing conan & cmake: python3 -m pip install conan cmake Install python3.9: sudo apt-get install python3.9 Install GCC and build essentials: sudo apt update && sudo apt upgrade sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test sudo apt install -y build-essential g++-11 Installing conan & cmake: python3.9 -m pip install conan cmake Install Homebrew: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Install latest version of Python 3.x: brew install python Install conan & cmake: python3 -m pip install conan cmake Install Rosetta (only required for M1 macs): /usr/sbin/softwareupdate --install-rosetta --agree-to-license Rosetta necessary for intel based cross compilers: We recommend using the choco package manager for windows as it allows easy installation of tools via the command line. To install choco , open PowerShell as an administrator and run the following command: Set-ExecutionPolicy Bypass -Scope Process -Force ; [System.Net.ServicePointManager] :: SecurityProtocol = [System.Net.ServicePointManager] :: SecurityProtocol -bor 3072 ; iex (( New-Object System . Net . WebClient ). DownloadString ( 'https://community.chocolatey.org/install.ps1' )) Tip If the choco command doesn't work after running this script try closing and opening again PowerShell. Now install python : choco install python Install gcc via the mingw : choco install mingw Install make for cmake: choco install make Installing conan & cmake: python3 -m pip install -U conan cmake","title":"\ud83e\uddf0 Install Prerequisites"},{"location":"prerequisites/#setting-up-conan","text":"First lets create a default profile: conan profile detect --force","title":"Setting up Conan"},{"location":"prerequisites/#add-libhal-trunk-repository-to-conan-remotes","text":"This allows conan to search for packages in the libhal-trunk repository, which is updated with every change to the libhal organizations code base. conan remote add libhal-trunk https://libhal.jfrog.io/artifactory/api/conan/trunk-conan","title":"Add libhal-trunk repository to conan remotes"},{"location":"prerequisites/#profile-setting-for-gcc-11-users","text":"Intel Linux ARM64 Linux M1 Mac Intel Mac Intel Windows ARM64 Windows If your host machine is using an intel core processor as its CPU then you'll want to use this default configuration. conan config install -sf profiles/x86_64/linux/ -tf profiles https://github.com/libhal/conan-config.git It is less likely your host desktop is an ARM64. This section is mostly for building applications and tests on a Raspberry PI or other SBC. But if you do have a laptop powered by an ARM64 core, then this is the correct configuration for you. conan config install -sf profiles/armv8/linux/ -tf profiles https://github.com/libhal/conan-config.git If your macbook uses an M1 processor then you'll want to use this default configuration. conan config install -sf profiles/armv8/mac/ -tf profiles https://github.com/libhal/conan-config.git If your macbook uses an Intel processor then you'll want to use this default configuration. conan config install -sf profiles/x86_64/mac/ -tf profiles https://github.com/libhal/conan-config.git If your windows machine uses an Intel processor then you'll want to use this default configuration. conan config install -sf profiles/x86_64/windows/ -tf profiles https://github.com/libhal/conan-config.git If you have a modern surface laptop with ARM64, then this may be the right choice for you. conan config install -sf profiles/armv8/windows/ -tf profiles https://github.com/libhal/conan-config.git","title":"Profile setting for GCC 11 users"},{"location":"style/","text":"\ud83c\udfa8 Style Guide S.0 Code Guidelines All guides follow the C++ Core Guidelines . S.1 Formatting Code shall follow libhal's .clang-format file, which uses the Mozilla C++ style format as a base with some adjustments. Code shall follow libhal's .naming.style file, which is very similar to the standard library naming convention: CamelCase for template parameters. CAP_CASE for MACROs (avoid MACROs in general). lowercase snake_case for everything else. prefix p_ for function parameters. prefix m_ for private/protected class member. Refrain from variable names with abbreviations where it can be helped. adc , pwm , and i2c are extremely common so it is fine to leave them as abbreviations. Most people know the abbreviations more than the words that make them up. But words like cnt should be count and cdl and cdh should be written out as clock_divider_low and clock_divider_high . Registers do get a pass if they directly reflect the names in the data sheet which will make looking them up easier in the future. Use #pragma once as the include guard for headers. Every file must end with a newline character. Every line in a file must stay within a 80 character limit. Exceptions to this rule are allowed. Use // NOLINT in these cases. Radix for bit manipulation: Only use binary ( 0b1000'0011 ) or hex ( 0x0FF0 ) for bit manipulation. Never use decimal or octal as this is harder to reason about for most programmers. Every public API must be documented with the doxygen style comments (CI will ensure that every public API is documented fully). Include the C++ header version of C headers such as <cstdint> vs <stdint.h> . S.2 Refrain from performing manual bit manipulation Use hal::bit from libhal-util library to perform bitwise operations operations. S.3 Refrain from using MACROS Only use macros if something cannot be done without using them. Usually macros can be replaced with constexpr or const variables or function calls. A case where macros are the only way is for HAL_CHECK() since there is no way to automatically generate the boiler plate for returning if a function returns and error in C++ and thus a macro is needed here to prevent possible mistakes in writing out the boilerplate. Only use preprocessor #if and the like if it is impossible to use if constexpr to achieve the same behavior. S.4 Never include C++ stream libraries Applications incur an automatic 150kB space penalty for including any of the ostream headers that also statically generate the global std::cout and the like objects. This happens even if the application never uses any part of <iostream> library. S.5 Refrain from memory allocations Interfaces and drivers should refrain from APIs that force memory allocations or implementations that allocate memory from heap. This means avoiding STL libraries that allocate such as std::string or std::vector . Many embedded system applications, especially the real time ones, do not allow dynamic memory allocations. There are many reasons for this that can be found MISRA C++ and AutoSAR. S.6 Drivers should not log to STDOUT or STDIN Peripheral drivers must NOT log to stdout or stderr. This means no calls to std::printf std::cout std::print (C++26's version of print based on std::format ) Consider using the file I/O libraries in C, C++, python or some other language. Would you, as a developer, ever imagine that opening, reading, writing, or closing a file would (write?) to your console? Especially if there did not exist a way to turn off logging. Most users would be very upset as this would not seem like the role of the file I/O library to spam the console. This gets even worse if a particular application has thousands of files and each operation is logging. The role of logging should be held by the application developer, not their drivers or helper functions, unless the purpose of the helper functions or driver is to write to console. S.7 Drivers should not purposefully halt OR terminate the application Drivers are not entitled to halt the execution of the application and thus any code block that would effectively end or halt the execution of the program without giving control back to the application are prohibited. As an example drivers should never call: - std::abort() - std::exit() - std::terminate() - any of their variants This includes placing an infinite loop block in a driver. An application should have control over how their application ends. A driver should report severe errors to the application and let the application decide the next steps. If a particular operation cannot be executed as intended, then hal::new_error() should be called. Constructors would be the only valid place to put an exit statement, because they cannot return errors only themselves. The solution to this is to use a factory function like so: Device Driver Library Peripheral Driver Library class device_driver { public : result < device_driver > create ( /* ... */ ) { // Perform operations that may fail here return device_driver ( /* ... */ ); } private : device_driver ( /* ... */ ) { // Constructors should never fail and thus any work done here must not // fail. } }; class peripheral_driver { public : // Since peripherals are constrained and have a finite set of values // This also ensures that the driver is only constructed once and afterwards // simply returns back a reference to that object. template < size_t PortNumber > // NOTE: Returns a reference not an object. // Objects are owned by the create function result < peripheral_driver &> create ( /* ... */ ) { // Perform operations that may fail here static peripheral_driver driver ( /* ... */ ); return driver ; } private : peripheral_driver ( /* ... */ ) { // ... } }; S.8 Drivers should not pollute the global namespace All drivers must be within the hal namespace or within their own bespoke namespace. Inclusion of a C header file full of register map structures is not allowed as it pollutes the global namespace and tends to result in name collisions. Care should be taken to ensure that the hal namespace is also as clean as possible by placing structures, enums, const data, and any other symbols into the driver's class's namespace like so: namespace hal :: target { class target { struct register_map { std :: uint32_t control1 ; std :: uint32_t control2 ; std :: uint32_t data ; std :: uint32_t status ; // .. }; struct control1_register { static constexpr auto channel_enable = hal :: bit :: range :: from < 0 , 7 > (); static constexpr auto peripheral_enable = hal :: bit :: range :: from < 8 > (); // ... }; // ... }; } S.9 Interface should follow the public private API Scheme See private virtual method for more details. Rationale can be found within that link as well. S.10 Avoid using bool S.10.1 As an object member bool has very poor information density and takes up 8-bits per entry. If only one bool is needed, then a bool is a fine object member. If multiple bool s are needed, then use a std::bitset along with static constexpr index positions in order to keep the density down to the lowest amount possible. S.10.2 As a parameter See the article \"Clean code: The curse of a boolean parameter\" for details as to why bool parameters are awful. bool is fine if it is the only parameter and it acts as a lexical switch, for example: // This is fine because it reads as set \"LED\" voltage \"level\" to \"FALSE\" led . level ( false ); // This is fine because it reads as set \"LED\" voltage \"level\" to \"TRUE\" led . level ( true ); S.11 Integrating third party libraries by source In general, third party libraries should NOT be integrated into a library by source. It should be depended upon using a package manager. But in some cases third party libraries must be included by source. In these cases, the third party libraries should be committed into a project, without modifications, into the include/<library_name>/third_party directory. After that commit, the third party libraries can be used by and integrated into the library code base, in a following commit. If a third party library is modified, that library must have a section at the top of the file with the following description: /** * [libhal] modifications to this file are as follows: * * 1. mod 1 * 2. mod 2 * 3. mod 3 * 4. mod 4 */ /** * <LICENSE GOES HERE!> */ Care must be taken to ensure that third party libraries do not conflict with the licenses of libhal libraries and permit direct integration as well as modification. Rationale: Makes keeping track of changes and the history of files easier to manage. S.12 Avoid std::atomic Avoid using std::atomic because of portability issues across devices in architectures. Especially when std::atomic is not fully supported by the compiler. Info target and processor libraries are allowed to use std::atomic if it is available with their cross compiler and toolchain. In this case, the we can know which target devices the software is running on, either the target itself, which we already know can support it, or on a host machine for unit testing, which is very likely to have a compiler that supports atomics. S.13 Avoid <thread> Embedded system compilers tend to not provide an implementation of <thread> because the choice of which threading model or multi-threading operating system is left to the developer. In general, #include <thread> will almost never work when cross compiling.","title":"\ud83c\udfa8 Style Guide"},{"location":"style/#style-guide","text":"","title":"\ud83c\udfa8 Style Guide"},{"location":"style/#s0-code-guidelines","text":"All guides follow the C++ Core Guidelines .","title":"S.0 Code Guidelines"},{"location":"style/#s1-formatting","text":"Code shall follow libhal's .clang-format file, which uses the Mozilla C++ style format as a base with some adjustments. Code shall follow libhal's .naming.style file, which is very similar to the standard library naming convention: CamelCase for template parameters. CAP_CASE for MACROs (avoid MACROs in general). lowercase snake_case for everything else. prefix p_ for function parameters. prefix m_ for private/protected class member. Refrain from variable names with abbreviations where it can be helped. adc , pwm , and i2c are extremely common so it is fine to leave them as abbreviations. Most people know the abbreviations more than the words that make them up. But words like cnt should be count and cdl and cdh should be written out as clock_divider_low and clock_divider_high . Registers do get a pass if they directly reflect the names in the data sheet which will make looking them up easier in the future. Use #pragma once as the include guard for headers. Every file must end with a newline character. Every line in a file must stay within a 80 character limit. Exceptions to this rule are allowed. Use // NOLINT in these cases. Radix for bit manipulation: Only use binary ( 0b1000'0011 ) or hex ( 0x0FF0 ) for bit manipulation. Never use decimal or octal as this is harder to reason about for most programmers. Every public API must be documented with the doxygen style comments (CI will ensure that every public API is documented fully). Include the C++ header version of C headers such as <cstdint> vs <stdint.h> .","title":"S.1 Formatting"},{"location":"style/#s2-refrain-from-performing-manual-bit-manipulation","text":"Use hal::bit from libhal-util library to perform bitwise operations operations.","title":"S.2 Refrain from performing manual bit manipulation"},{"location":"style/#s3-refrain-from-using-macros","text":"Only use macros if something cannot be done without using them. Usually macros can be replaced with constexpr or const variables or function calls. A case where macros are the only way is for HAL_CHECK() since there is no way to automatically generate the boiler plate for returning if a function returns and error in C++ and thus a macro is needed here to prevent possible mistakes in writing out the boilerplate. Only use preprocessor #if and the like if it is impossible to use if constexpr to achieve the same behavior.","title":"S.3 Refrain from using MACROS"},{"location":"style/#s4-never-include-c-stream-libraries","text":"Applications incur an automatic 150kB space penalty for including any of the ostream headers that also statically generate the global std::cout and the like objects. This happens even if the application never uses any part of <iostream> library.","title":"S.4 Never include C++ stream libraries"},{"location":"style/#s5-refrain-from-memory-allocations","text":"Interfaces and drivers should refrain from APIs that force memory allocations or implementations that allocate memory from heap. This means avoiding STL libraries that allocate such as std::string or std::vector . Many embedded system applications, especially the real time ones, do not allow dynamic memory allocations. There are many reasons for this that can be found MISRA C++ and AutoSAR.","title":"S.5 Refrain from memory allocations"},{"location":"style/#s6-drivers-should-not-log-to-stdout-or-stdin","text":"Peripheral drivers must NOT log to stdout or stderr. This means no calls to std::printf std::cout std::print (C++26's version of print based on std::format ) Consider using the file I/O libraries in C, C++, python or some other language. Would you, as a developer, ever imagine that opening, reading, writing, or closing a file would (write?) to your console? Especially if there did not exist a way to turn off logging. Most users would be very upset as this would not seem like the role of the file I/O library to spam the console. This gets even worse if a particular application has thousands of files and each operation is logging. The role of logging should be held by the application developer, not their drivers or helper functions, unless the purpose of the helper functions or driver is to write to console.","title":"S.6 Drivers should not log to STDOUT or STDIN"},{"location":"style/#s7-drivers-should-not-purposefully-halt-or-terminate-the-application","text":"Drivers are not entitled to halt the execution of the application and thus any code block that would effectively end or halt the execution of the program without giving control back to the application are prohibited. As an example drivers should never call: - std::abort() - std::exit() - std::terminate() - any of their variants This includes placing an infinite loop block in a driver. An application should have control over how their application ends. A driver should report severe errors to the application and let the application decide the next steps. If a particular operation cannot be executed as intended, then hal::new_error() should be called. Constructors would be the only valid place to put an exit statement, because they cannot return errors only themselves. The solution to this is to use a factory function like so: Device Driver Library Peripheral Driver Library class device_driver { public : result < device_driver > create ( /* ... */ ) { // Perform operations that may fail here return device_driver ( /* ... */ ); } private : device_driver ( /* ... */ ) { // Constructors should never fail and thus any work done here must not // fail. } }; class peripheral_driver { public : // Since peripherals are constrained and have a finite set of values // This also ensures that the driver is only constructed once and afterwards // simply returns back a reference to that object. template < size_t PortNumber > // NOTE: Returns a reference not an object. // Objects are owned by the create function result < peripheral_driver &> create ( /* ... */ ) { // Perform operations that may fail here static peripheral_driver driver ( /* ... */ ); return driver ; } private : peripheral_driver ( /* ... */ ) { // ... } };","title":"S.7 Drivers should not purposefully halt OR terminate the application"},{"location":"style/#s8-drivers-should-not-pollute-the-global-namespace","text":"All drivers must be within the hal namespace or within their own bespoke namespace. Inclusion of a C header file full of register map structures is not allowed as it pollutes the global namespace and tends to result in name collisions. Care should be taken to ensure that the hal namespace is also as clean as possible by placing structures, enums, const data, and any other symbols into the driver's class's namespace like so: namespace hal :: target { class target { struct register_map { std :: uint32_t control1 ; std :: uint32_t control2 ; std :: uint32_t data ; std :: uint32_t status ; // .. }; struct control1_register { static constexpr auto channel_enable = hal :: bit :: range :: from < 0 , 7 > (); static constexpr auto peripheral_enable = hal :: bit :: range :: from < 8 > (); // ... }; // ... }; }","title":"S.8 Drivers should not pollute the global namespace"},{"location":"style/#s9-interface-should-follow-the-public-private-api-scheme","text":"See private virtual method for more details. Rationale can be found within that link as well.","title":"S.9 Interface should follow the public private API Scheme"},{"location":"style/#s10-avoid-using-bool","text":"","title":"S.10 Avoid using bool"},{"location":"style/#s101-as-an-object-member","text":"bool has very poor information density and takes up 8-bits per entry. If only one bool is needed, then a bool is a fine object member. If multiple bool s are needed, then use a std::bitset along with static constexpr index positions in order to keep the density down to the lowest amount possible.","title":"S.10.1 As an object member"},{"location":"style/#s102-as-a-parameter","text":"See the article \"Clean code: The curse of a boolean parameter\" for details as to why bool parameters are awful. bool is fine if it is the only parameter and it acts as a lexical switch, for example: // This is fine because it reads as set \"LED\" voltage \"level\" to \"FALSE\" led . level ( false ); // This is fine because it reads as set \"LED\" voltage \"level\" to \"TRUE\" led . level ( true );","title":"S.10.2 As a parameter"},{"location":"style/#s11-integrating-third-party-libraries-by-source","text":"In general, third party libraries should NOT be integrated into a library by source. It should be depended upon using a package manager. But in some cases third party libraries must be included by source. In these cases, the third party libraries should be committed into a project, without modifications, into the include/<library_name>/third_party directory. After that commit, the third party libraries can be used by and integrated into the library code base, in a following commit. If a third party library is modified, that library must have a section at the top of the file with the following description: /** * [libhal] modifications to this file are as follows: * * 1. mod 1 * 2. mod 2 * 3. mod 3 * 4. mod 4 */ /** * <LICENSE GOES HERE!> */ Care must be taken to ensure that third party libraries do not conflict with the licenses of libhal libraries and permit direct integration as well as modification. Rationale: Makes keeping track of changes and the history of files easier to manage.","title":"S.11 Integrating third party libraries by source"},{"location":"style/#s12-avoid-stdatomic","text":"Avoid using std::atomic because of portability issues across devices in architectures. Especially when std::atomic is not fully supported by the compiler. Info target and processor libraries are allowed to use std::atomic if it is available with their cross compiler and toolchain. In this case, the we can know which target devices the software is running on, either the target itself, which we already know can support it, or on a host machine for unit testing, which is very likely to have a compiler that supports atomics.","title":"S.12 Avoid std::atomic"},{"location":"style/#s13-avoid-thread","text":"Embedded system compilers tend to not provide an implementation of <thread> because the choice of which threading model or multi-threading operating system is left to the developer. In general, #include <thread> will almost never work when cross compiling.","title":"S.13 Avoid &lt;thread&gt;"},{"location":"trying_out/","text":"\ud83d\ude80 Trying out libhal Necessary Parts In order to complete this tutorial you'll need these parts: STM32F103 MicroMod or LPC4078 MicroMod or SJ2 Board Sparkfun ATP board or SJ3 Board or SJ2 Board STLink V2 STLink V2 to JTAG connector Info libhal development kit is in development \ud83d\udee0\ufe0f Building Demos Make sure to complete \ud83e\uddf0 Install Prerequisites Cloning the target libraries Clone the target library you would like to run the demos for. You can download just one or both if you have both devices. LPC4078 STM32F103 \u274c git clone https://github.com/libhal/libhal-lpc40 cd libhal-lpc40/demo git clone https://github.com/libhal/libhal-stm32f1 cd libhal-stm32f1/demo Building using Conan & CMake To build using conan and cmake, you just need to run the following: conan build . -b missing Note You only have to include -b missing if you get an error stating that the prebuilt binaries are missing. -b missing will build them locally for your machine. After which those libraries will be cached on your machine and you'll no longer need to include those arguments. Tip If you want to create release packages which enables optimizations, you will need to add the -s build_type=Release to your conan build command: conan build . -b missing -s build_type = Release When this completes you should have some applications in the build/Debug/ with names such as lpc4078_uart.elf or stm32f103_blinker.elf . \ud83d\udcbe Uploading Demos to Device There are python programs built for uploading binary files to devices. First step is connecting your MicroMod carrier board to your computer using the USB-C connector. Question Don't know which serial port to use? Use this guide Find Arduino Port on Windows, Mac, and Linux from the MATLAB docs to help. Simply ignore that its made for Arduino, this guide will work for any serial USB device. LPC4078 STM32F10X \u274c Install the nxpprog flashing software for LPC devices: python3 -m pip install nxpprog Tip On Ubuntu 22.04 you will need to use the command python3.9 because the default python is usually 3.8. python3.9 -m pip install nxpprog nxpprog --control --binary \"build/Debug/lpc4078_uart.elf.bin\" --device \"/dev/tty.usbserial-140\" Replace /dev/tty.usbserial-140 with the correct port. Use \"build/Debug/lpc4078_uart.elf.bin\" or replace it with any other application to be uploaded. Install the stm32loader flashing software for STM32 devices: python3 -m pip install stm32loader stm32loader.py -p /dev/tty.usbserial-140 -e -w -v \"build/Debug/stm32f103_uart.elf.bin\" Replace /dev/tty.usbserial-140 with the correct port. Use \"build/Debug/stm32f103_uart.elf.bin\" or replace it with any other application to be uploaded.","title":"\ud83d\ude80 Trying out libhal"},{"location":"trying_out/#trying-out-libhal","text":"","title":"\ud83d\ude80 Trying out libhal"},{"location":"trying_out/#necessary-parts","text":"In order to complete this tutorial you'll need these parts: STM32F103 MicroMod or LPC4078 MicroMod or SJ2 Board Sparkfun ATP board or SJ3 Board or SJ2 Board STLink V2 STLink V2 to JTAG connector Info libhal development kit is in development","title":"Necessary Parts"},{"location":"trying_out/#building-demos","text":"Make sure to complete \ud83e\uddf0 Install Prerequisites","title":"\ud83d\udee0\ufe0f Building Demos"},{"location":"trying_out/#cloning-the-target-libraries","text":"Clone the target library you would like to run the demos for. You can download just one or both if you have both devices. LPC4078 STM32F103 \u274c git clone https://github.com/libhal/libhal-lpc40 cd libhal-lpc40/demo git clone https://github.com/libhal/libhal-stm32f1 cd libhal-stm32f1/demo","title":"Cloning the target libraries"},{"location":"trying_out/#building-using-conan-cmake","text":"To build using conan and cmake, you just need to run the following: conan build . -b missing Note You only have to include -b missing if you get an error stating that the prebuilt binaries are missing. -b missing will build them locally for your machine. After which those libraries will be cached on your machine and you'll no longer need to include those arguments. Tip If you want to create release packages which enables optimizations, you will need to add the -s build_type=Release to your conan build command: conan build . -b missing -s build_type = Release When this completes you should have some applications in the build/Debug/ with names such as lpc4078_uart.elf or stm32f103_blinker.elf .","title":"Building using Conan &amp; CMake"},{"location":"trying_out/#uploading-demos-to-device","text":"There are python programs built for uploading binary files to devices. First step is connecting your MicroMod carrier board to your computer using the USB-C connector. Question Don't know which serial port to use? Use this guide Find Arduino Port on Windows, Mac, and Linux from the MATLAB docs to help. Simply ignore that its made for Arduino, this guide will work for any serial USB device. LPC4078 STM32F10X \u274c Install the nxpprog flashing software for LPC devices: python3 -m pip install nxpprog Tip On Ubuntu 22.04 you will need to use the command python3.9 because the default python is usually 3.8. python3.9 -m pip install nxpprog nxpprog --control --binary \"build/Debug/lpc4078_uart.elf.bin\" --device \"/dev/tty.usbserial-140\" Replace /dev/tty.usbserial-140 with the correct port. Use \"build/Debug/lpc4078_uart.elf.bin\" or replace it with any other application to be uploaded. Install the stm32loader flashing software for STM32 devices: python3 -m pip install stm32loader stm32loader.py -p /dev/tty.usbserial-140 -e -w -v \"build/Debug/stm32f103_uart.elf.bin\" Replace /dev/tty.usbserial-140 with the correct port. Use \"build/Debug/stm32f103_uart.elf.bin\" or replace it with any other application to be uploaded.","title":"\ud83d\udcbe Uploading Demos to Device"},{"location":"directory/status/","text":"Library Status Repo CI State Coverage Latest Version libhal/libhal-__platform__ libhal/libhal-stm32f1 libhal/libhal-esp8266 libhal/libhal-__device__ libhal/libhal-mpu libhal/libhal-pca libhal/libhal-rmd libhal/libhal-tmp libhal/libhal-mock libhal/libhal-soft libhal/libhal-lpc40 libhal/libhal-util libhal/libhal libhal/libhal-armcortex","title":"Library Status"},{"location":"directory/status/#library-status","text":"Repo CI State Coverage Latest Version libhal/libhal-__platform__ libhal/libhal-stm32f1 libhal/libhal-esp8266 libhal/libhal-__device__ libhal/libhal-mpu libhal/libhal-pca libhal/libhal-rmd libhal/libhal-tmp libhal/libhal-mock libhal/libhal-soft libhal/libhal-lpc40 libhal/libhal-util libhal/libhal libhal/libhal-armcortex","title":"Library Status"},{"location":"how-to/application/","text":"\ud83d\udd3a Application Libraries","title":"\ud83d\udd3a Application Libraries"},{"location":"how-to/application/#application-libraries","text":"","title":"\ud83d\udd3a Application Libraries"},{"location":"how-to/arm_cortex_bringup/","text":"\ud83d\udd38 Bare-Metal ARM Cortex Target Bring-Up This guide will step you through making a libhal + conan target library for a arm processor microcontroller. Unlike libhal applications that can be executed on a machine running an OS like linux, example Raspberry Pi and Beagle Boards, you cannot just execute the binary. This guide assumes that libhal-library was used as a template and has already updated and changed all of the names from libhal-library to the appropriate library name. In order to build an application that can be loaded and executed onto a microcontroller you only need: Add libhal-armcortex as a dependency Provide a linker script for each microcontroller Determine minimum compiler flags for each microcontroller Provide a library component for that microcontroller The rest can be handled by the arm-gnu-embedded-toolchain 's crt0 implementation, the arm-gnu-embedded-toolchain conan package and the libhal-armcortex conan package. Adding the libhal-armcortex dependency Simply add libhal-armcortex to your requirements() method: def requirements ( self ): # ... self . requires ( \"libhal-armcortex/[^1.0.1]\" ) Writing the linker scripts Setup linker script directory Create a linker_scripts directory at the root of the library package. Add linker_scripts/* directory to the export sources in the package conanfile.py , like so: exports_sources = \"include/*\" , \"linker_scripts/*\" , \"tests/*\" , \"LICENSE\" Finding linker scripts info Lets consider the lpc4074 microcontroller. What you'll need to figure out is: Flash memory address & size Ram memory address & size These sections are part of whats called the \"memory map\". Most modern day systems use a system called \"Memory-mapped I/O\" which means that the system uses the same address space to address both memory and I/O devices. In this case we simply want to find the addresses of the flash memory and ram memory. This information can be found in the data sheet or user manual of the chip. The LPC40 series of microcontrollers will be used for this example: The memory map can be found on page 52 of the LPC408X_7X.pdf data sheet or page 14 of the UM10562.pdf user manual. Figure 1. LPC40xx Memory Map Here you can see that flash starts at address 0x00000000 for all sizes of flash memory. The SRAM locations all start at 0x10000000 for all sizes of SRAM. This chart does not provide which chips have which ram and flash sizes. Looking through the data sheet and searching for terms like \"part numbers\", \"ordering options\", or even just the number 512 (the maximum flash size), eventually this section will appear: Figure 2. LPC40xx Part Ordering Info part 1 Figure 3. LPC40xx Part Ordering Info part 2 Now all of the information to write the linker scripts is available: lpc4072.ld lpc4074.ld lpc4076.ld lpc4078.ld lpc4088.ld __flash = 0x00000000; __flash_size = 64K; __ram = 0x10000000; __ram_size = 16K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 128K; __ram = 0x10000000; __ram_size = 32K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 256K; __ram = 0x10000000; __ram_size = 64K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 512K; __ram = 0x10000000; __ram_size = 64K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 512K; __ram = 0x10000000; __ram_size = 64K; INCLUDE \"libhal-armcortex/standard.ld\" Question You may be wondering why the RAM size is 64kB and not 96kB for some of the linker scripts and thats due to the fact that the LPC40xx series has a dual SRAM architecture. To keep this simple, only the largest RAM block is supported. The linker script only needs 4 lines as libhal-armcortex provides a standard linker script for ARM microcontrollers supporting 1 flash memory and 1 ram device. Defining the __flash , __flash_size , __ram , and __ram_size linker script variables is all that is needed to make a usable linker script. There are plans to support dual flash, dual ram and other varieties of flash and ram combinations in the future in libhal-armcortex . Warning Many of the microcontrollers come in different packages and may have some differences in the number of peripherals they support, pins they have and performance. The linker script does not need to worry about such differences and thus, a linker script should NOT be made for every possible chip variety in the series but for the common flash sizes and ram sizes for each. Compiler flags Processor flags The data sheet will include information about the processor. The compiler flag will match the following based on the CPU: -mcpu=cortex-m0 -mcpu=cortex-m0plus (cortex-M0+) -mcpu=cortex-m1 -mcpu=cortex-m3 -mcpu=cortex-m4 -mcpu=cortex-m7 -mcpu=cortex-m23 -mcpu=cortex-m33 -mcpu=cortex-m35p -mcpu=cortex-m55 -mcpu=cortex-m85 -mcpu=cortex-m1.small-multiply -mcpu=cortex-m0.small-multiply -mcpu=cortex-m0plus.small-multiply Floating Point Support After one of the following to the architecture flags: -mfloat-abi=soft : if the processor is an cortex-m3 or below -mfloat-abi=softfp : if the processor is a cortex-m4 and above AND also has a floating point unit. This can be determined by searching the data sheet. Creating components for the library libhal target library's split up the library into components, one for each microcontroller variant. For LPC40 that split would look like: libhal::lpc4072 , libhal::lpc4074 , libhal::lpc4076 , libhal::lpc4078 , and libhal::lpc4088 . When a build system, for example, uses the libhal::lpc4078 component, it includes the necessary compiler flags and linker script selection. Along with these components, will be a special generic component named libhal::lpc which does not provide any compiler flags or linker script. This special target is used for applications that want to use their own linker script, or for software running on a host machine like simulations or unit tests. To add components it must be added in the package_info method of the ConanFile package class. Here is what it looks like for the libhal-lpc library. Copy this section and tailor it to your needs. def package_info ( self ): # Specify, for the component, all requirements of the package requirements_list = [ \"libhal::libhal\" , \"libhal-util::libhal-util\" , \"libhal-armcortex::libhal-armcortex\" , \"ring-span-lite::ring-span-lite\" ] # List of REQUIRED compiler flags for the gnu-arm-embedded-toolchain for some # of the chips. These are determined by the capabilities of the chip. # For example all but the lpc4072 and lpc4074 have hardware floating point # arithmetic support so they ought to use \"float-abi=softfp\" which uses the # floating point hardware BUT is ABI compatible with the software # implementation. m4f_architecture_flags = [ \"-mcpu=cortex-m4\" , \"-mfloat-abi=softfp\" , ] # List of REQUIRED compiler flags for the gnu-arm-embedded-toolchain for # some of the chips. These are determined by the capabilities of the chip. # For example the lpc4072 and lpc4074 do not have hardware floating point # arithmetic support so they must use \"float-abi=soft\" for a software # implementation. m4_architecture_flags = [ \"-mcpu=cortex-m4\" , \"-mfloat-abi=soft\" ] # Create a path to the linker_script directory which resides in the # package's package_folder. linker_path = os . path . join ( self . package_folder , \"linker_script\" ) # Set the cmake file name self . cpp_info . set_property ( \"cmake_file_name\" , \"libhal-lpc\" ) # All the package to be found in anyway with cmake self . cpp_info . set_property ( \"cmake_find_mode\" , \"both\" ) # Create the special/generic component \"lpc\" and set its component name self . cpp_info . components [ \"lpc\" ] . set_property ( \"cmake_target_name\" , \"libhal::lpc\" ) # This is where we add the path to our linker scripts to the set of linker # flags. self . cpp_info . components [ \"lpc\" ] . exelinkflags . append ( \"-L\" + linker_path ) # Add the list of requirements to the generic component self . cpp_info . components [ \"lpc\" ] . requires = requirements_list # Helper function for creating components def create_component ( self , component , flags ): link_script = \"-Tlibhal-lpc/\" + component + \".ld\" component_name = \"libhal::\" + component self . cpp_info . components [ component ] . set_property ( \"cmake_target_name\" , component_name ) # Make the special component the only requirement for the component, # inheriting all of the transitive dependencies. self . cpp_info . components [ component ] . requires = [ \"lpc\" ] # Add the link script and flags to the component's linker flags and # compiler flags self . cpp_info . components [ component ] . exelinkflags . append ( link_script ) self . cpp_info . components [ component ] . exelinkflags . extend ( flags ) # Add flags to the cflags & cxxflags to ensure that each compilation unit # Knows the instruction set and float ABI self . cpp_info . components [ component ] . cflags = flags self . cpp_info . components [ component ] . cxxflags = flags # Create the components for each chip. create_component ( self , \"lpc4072\" , m4_architecture_flags ) create_component ( self , \"lpc4074\" , m4_architecture_flags ) create_component ( self , \"lpc4076\" , m4f_architecture_flags ) create_component ( self , \"lpc4078\" , m4f_architecture_flags ) create_component ( self , \"lpc4088\" , m4f_architecture_flags ) Verifying Creating the package Run conan create . in the folder with the conanfile.py recipe in it. The test package and build stages should show something like this during the cmake phase: -- Conan: Component target declared 'libhal::lpc' -- Conan: Component target declared 'libhal::lpc4072' -- Conan: Component target declared 'libhal::lpc4074' -- Conan: Component target declared 'libhal::lpc4076' -- Conan: Component target declared 'libhal::lpc4078' -- Conan: Component target declared 'libhal::lpc4088' Testing out a demo Create a demo and have it require the library. In this case the demo conafile.py may include: from conan import ConanFile from conan.tools.cmake import CMake , cmake_layout class Lpc40xxDemos ( ConanFile ): settings = \"compiler\" , \"build_type\" generators = \"CMakeToolchain\" , \"CMakeDeps\" , \"VirtualBuildEnv\" def requirements ( self ): self . requires ( \"libhal-lpc/1.1.4\" ) # <-- change this self . requires ( \"libhal-util/[^1.0.0]\" ) # <-- update this if necessary self . tool_requires ( \"gnu-arm-embedded-toolchain/11.3.0\" ) self . tool_requires ( \"cmake-arm-embedded/0.1.1\" ) def layout ( self ): cmake_layout ( self ) def build ( self ): cmake = CMake ( self ) cmake . configure () cmake . build () Change the library name to the library you are creating. self . tool_requires ( \"gnu-arm-embedded-toolchain/11.3.0\" ) self . tool_requires ( \"cmake-arm-embedded/0.1.1\" ) The above two requirements are required to download and install the toolchain/compiler and the cmake toolchain/helper files. The project should compile if everything was done correctly.","title":"\ud83d\udd38 Bare-Metal ARM Cortex Target Bring-Up"},{"location":"how-to/arm_cortex_bringup/#bare-metal-arm-cortex-target-bring-up","text":"This guide will step you through making a libhal + conan target library for a arm processor microcontroller. Unlike libhal applications that can be executed on a machine running an OS like linux, example Raspberry Pi and Beagle Boards, you cannot just execute the binary. This guide assumes that libhal-library was used as a template and has already updated and changed all of the names from libhal-library to the appropriate library name. In order to build an application that can be loaded and executed onto a microcontroller you only need: Add libhal-armcortex as a dependency Provide a linker script for each microcontroller Determine minimum compiler flags for each microcontroller Provide a library component for that microcontroller The rest can be handled by the arm-gnu-embedded-toolchain 's crt0 implementation, the arm-gnu-embedded-toolchain conan package and the libhal-armcortex conan package.","title":"\ud83d\udd38 Bare-Metal ARM Cortex Target Bring-Up"},{"location":"how-to/arm_cortex_bringup/#adding-the-libhal-armcortex-dependency","text":"Simply add libhal-armcortex to your requirements() method: def requirements ( self ): # ... self . requires ( \"libhal-armcortex/[^1.0.1]\" )","title":"Adding the libhal-armcortex dependency"},{"location":"how-to/arm_cortex_bringup/#writing-the-linker-scripts","text":"","title":"Writing the linker scripts"},{"location":"how-to/arm_cortex_bringup/#setup-linker-script-directory","text":"Create a linker_scripts directory at the root of the library package. Add linker_scripts/* directory to the export sources in the package conanfile.py , like so: exports_sources = \"include/*\" , \"linker_scripts/*\" , \"tests/*\" , \"LICENSE\"","title":"Setup linker script directory"},{"location":"how-to/arm_cortex_bringup/#finding-linker-scripts-info","text":"Lets consider the lpc4074 microcontroller. What you'll need to figure out is: Flash memory address & size Ram memory address & size These sections are part of whats called the \"memory map\". Most modern day systems use a system called \"Memory-mapped I/O\" which means that the system uses the same address space to address both memory and I/O devices. In this case we simply want to find the addresses of the flash memory and ram memory. This information can be found in the data sheet or user manual of the chip. The LPC40 series of microcontrollers will be used for this example: The memory map can be found on page 52 of the LPC408X_7X.pdf data sheet or page 14 of the UM10562.pdf user manual. Figure 1. LPC40xx Memory Map Here you can see that flash starts at address 0x00000000 for all sizes of flash memory. The SRAM locations all start at 0x10000000 for all sizes of SRAM. This chart does not provide which chips have which ram and flash sizes. Looking through the data sheet and searching for terms like \"part numbers\", \"ordering options\", or even just the number 512 (the maximum flash size), eventually this section will appear: Figure 2. LPC40xx Part Ordering Info part 1 Figure 3. LPC40xx Part Ordering Info part 2 Now all of the information to write the linker scripts is available: lpc4072.ld lpc4074.ld lpc4076.ld lpc4078.ld lpc4088.ld __flash = 0x00000000; __flash_size = 64K; __ram = 0x10000000; __ram_size = 16K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 128K; __ram = 0x10000000; __ram_size = 32K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 256K; __ram = 0x10000000; __ram_size = 64K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 512K; __ram = 0x10000000; __ram_size = 64K; INCLUDE \"libhal-armcortex/standard.ld\" __flash = 0x00000000; __flash_size = 512K; __ram = 0x10000000; __ram_size = 64K; INCLUDE \"libhal-armcortex/standard.ld\" Question You may be wondering why the RAM size is 64kB and not 96kB for some of the linker scripts and thats due to the fact that the LPC40xx series has a dual SRAM architecture. To keep this simple, only the largest RAM block is supported. The linker script only needs 4 lines as libhal-armcortex provides a standard linker script for ARM microcontrollers supporting 1 flash memory and 1 ram device. Defining the __flash , __flash_size , __ram , and __ram_size linker script variables is all that is needed to make a usable linker script. There are plans to support dual flash, dual ram and other varieties of flash and ram combinations in the future in libhal-armcortex . Warning Many of the microcontrollers come in different packages and may have some differences in the number of peripherals they support, pins they have and performance. The linker script does not need to worry about such differences and thus, a linker script should NOT be made for every possible chip variety in the series but for the common flash sizes and ram sizes for each.","title":"Finding linker scripts info"},{"location":"how-to/arm_cortex_bringup/#compiler-flags","text":"","title":"Compiler flags"},{"location":"how-to/arm_cortex_bringup/#processor-flags","text":"The data sheet will include information about the processor. The compiler flag will match the following based on the CPU: -mcpu=cortex-m0 -mcpu=cortex-m0plus (cortex-M0+) -mcpu=cortex-m1 -mcpu=cortex-m3 -mcpu=cortex-m4 -mcpu=cortex-m7 -mcpu=cortex-m23 -mcpu=cortex-m33 -mcpu=cortex-m35p -mcpu=cortex-m55 -mcpu=cortex-m85 -mcpu=cortex-m1.small-multiply -mcpu=cortex-m0.small-multiply -mcpu=cortex-m0plus.small-multiply","title":"Processor flags"},{"location":"how-to/arm_cortex_bringup/#floating-point-support","text":"After one of the following to the architecture flags: -mfloat-abi=soft : if the processor is an cortex-m3 or below -mfloat-abi=softfp : if the processor is a cortex-m4 and above AND also has a floating point unit. This can be determined by searching the data sheet.","title":"Floating Point Support"},{"location":"how-to/arm_cortex_bringup/#creating-components-for-the-library","text":"libhal target library's split up the library into components, one for each microcontroller variant. For LPC40 that split would look like: libhal::lpc4072 , libhal::lpc4074 , libhal::lpc4076 , libhal::lpc4078 , and libhal::lpc4088 . When a build system, for example, uses the libhal::lpc4078 component, it includes the necessary compiler flags and linker script selection. Along with these components, will be a special generic component named libhal::lpc which does not provide any compiler flags or linker script. This special target is used for applications that want to use their own linker script, or for software running on a host machine like simulations or unit tests. To add components it must be added in the package_info method of the ConanFile package class. Here is what it looks like for the libhal-lpc library. Copy this section and tailor it to your needs. def package_info ( self ): # Specify, for the component, all requirements of the package requirements_list = [ \"libhal::libhal\" , \"libhal-util::libhal-util\" , \"libhal-armcortex::libhal-armcortex\" , \"ring-span-lite::ring-span-lite\" ] # List of REQUIRED compiler flags for the gnu-arm-embedded-toolchain for some # of the chips. These are determined by the capabilities of the chip. # For example all but the lpc4072 and lpc4074 have hardware floating point # arithmetic support so they ought to use \"float-abi=softfp\" which uses the # floating point hardware BUT is ABI compatible with the software # implementation. m4f_architecture_flags = [ \"-mcpu=cortex-m4\" , \"-mfloat-abi=softfp\" , ] # List of REQUIRED compiler flags for the gnu-arm-embedded-toolchain for # some of the chips. These are determined by the capabilities of the chip. # For example the lpc4072 and lpc4074 do not have hardware floating point # arithmetic support so they must use \"float-abi=soft\" for a software # implementation. m4_architecture_flags = [ \"-mcpu=cortex-m4\" , \"-mfloat-abi=soft\" ] # Create a path to the linker_script directory which resides in the # package's package_folder. linker_path = os . path . join ( self . package_folder , \"linker_script\" ) # Set the cmake file name self . cpp_info . set_property ( \"cmake_file_name\" , \"libhal-lpc\" ) # All the package to be found in anyway with cmake self . cpp_info . set_property ( \"cmake_find_mode\" , \"both\" ) # Create the special/generic component \"lpc\" and set its component name self . cpp_info . components [ \"lpc\" ] . set_property ( \"cmake_target_name\" , \"libhal::lpc\" ) # This is where we add the path to our linker scripts to the set of linker # flags. self . cpp_info . components [ \"lpc\" ] . exelinkflags . append ( \"-L\" + linker_path ) # Add the list of requirements to the generic component self . cpp_info . components [ \"lpc\" ] . requires = requirements_list # Helper function for creating components def create_component ( self , component , flags ): link_script = \"-Tlibhal-lpc/\" + component + \".ld\" component_name = \"libhal::\" + component self . cpp_info . components [ component ] . set_property ( \"cmake_target_name\" , component_name ) # Make the special component the only requirement for the component, # inheriting all of the transitive dependencies. self . cpp_info . components [ component ] . requires = [ \"lpc\" ] # Add the link script and flags to the component's linker flags and # compiler flags self . cpp_info . components [ component ] . exelinkflags . append ( link_script ) self . cpp_info . components [ component ] . exelinkflags . extend ( flags ) # Add flags to the cflags & cxxflags to ensure that each compilation unit # Knows the instruction set and float ABI self . cpp_info . components [ component ] . cflags = flags self . cpp_info . components [ component ] . cxxflags = flags # Create the components for each chip. create_component ( self , \"lpc4072\" , m4_architecture_flags ) create_component ( self , \"lpc4074\" , m4_architecture_flags ) create_component ( self , \"lpc4076\" , m4f_architecture_flags ) create_component ( self , \"lpc4078\" , m4f_architecture_flags ) create_component ( self , \"lpc4088\" , m4f_architecture_flags )","title":"Creating components for the library"},{"location":"how-to/arm_cortex_bringup/#verifying","text":"","title":"Verifying"},{"location":"how-to/arm_cortex_bringup/#creating-the-package","text":"Run conan create . in the folder with the conanfile.py recipe in it. The test package and build stages should show something like this during the cmake phase: -- Conan: Component target declared 'libhal::lpc' -- Conan: Component target declared 'libhal::lpc4072' -- Conan: Component target declared 'libhal::lpc4074' -- Conan: Component target declared 'libhal::lpc4076' -- Conan: Component target declared 'libhal::lpc4078' -- Conan: Component target declared 'libhal::lpc4088'","title":"Creating the package"},{"location":"how-to/arm_cortex_bringup/#testing-out-a-demo","text":"Create a demo and have it require the library. In this case the demo conafile.py may include: from conan import ConanFile from conan.tools.cmake import CMake , cmake_layout class Lpc40xxDemos ( ConanFile ): settings = \"compiler\" , \"build_type\" generators = \"CMakeToolchain\" , \"CMakeDeps\" , \"VirtualBuildEnv\" def requirements ( self ): self . requires ( \"libhal-lpc/1.1.4\" ) # <-- change this self . requires ( \"libhal-util/[^1.0.0]\" ) # <-- update this if necessary self . tool_requires ( \"gnu-arm-embedded-toolchain/11.3.0\" ) self . tool_requires ( \"cmake-arm-embedded/0.1.1\" ) def layout ( self ): cmake_layout ( self ) def build ( self ): cmake = CMake ( self ) cmake . configure () cmake . build () Change the library name to the library you are creating. self . tool_requires ( \"gnu-arm-embedded-toolchain/11.3.0\" ) self . tool_requires ( \"cmake-arm-embedded/0.1.1\" ) The above two requirements are required to download and install the toolchain/compiler and the cmake toolchain/helper files. The project should compile if everything was done correctly.","title":"Testing out a demo"},{"location":"how-to/device/","text":"\ud83d\udd39 Device Libraries Info Documentation coming soon...","title":"\ud83d\udd39 Device Libraries"},{"location":"how-to/device/#device-libraries","text":"Info Documentation coming soon...","title":"\ud83d\udd39 Device Libraries"},{"location":"how-to/project/","text":"\ud83c\udd95 Creating a new Project In this example we create a project using the CMake build system. In order to make a project you need 5 files: conanfile.txt : list of project dependencies. CMakeLists.txt : instructions describing the project's source files, executables and how to build them. main.cpp : application software libhal.tweaks.hpp : configuration file for libhal newlib.cpp : definitions of low level C functions Quick Start Clone this starter project: git clone https://github.com/libhal/libhal-starter.git Creating the conanfile.txt A standard libhal conanfile.txt will look like this: [requires] libhal-lpc40/1.1.6 [tool_requires] gnu-arm-embedded-toolchain/11.3.0 cmake-arm-embedded/0.1.1 [generators] CMakeToolchain CMakeDeps [requires] lists the project dependencies. Each libhal project needs a target library and this example uses libhal-lpc40 which is used for the SJ2 board or the LPC4078 micromod. [tool_requires] lists the tools that are needed to build the project. gnu-arm-embedded-toolchain/11.3.0 brings in the ARM GCC cross compiler which is used to compile to the code for ARM Cortex microcontroller. cmake-arm-embedded/0.1.1 brings in cmake helper scripts and toolchain files for configuring cmake for the cross compiler. [generators] list the generators which generate files for the project build systems. CMakeToolchain : Generates toolchain cmake scripts based on the conan package recipe information. CMakeDeps : Generates cmake package/configuration files for each library which can be Making the CMakeLists.txt file Below is the minimal amount of cmake code needed for a libhal project: cmake_minimum_required ( VERSION 3.20 ) project ( project_name.elf VERSION 0.0.1 LANGUAGES CXX ) find_package ( libhal-lpc40 REQUIRED CONFIG ) add_executable ( ${ PROJECT_NAME } main.cpp newlib.cpp ) target_compile_features ( ${ PROJECT_NAME } PRIVATE cxx_std_20 ) target_include_directories ( ${ PROJECT_NAME } PUBLIC . ) target_link_libraries ( ${ PROJECT_NAME } PRIVATE libhal::lpc4078 ) arm_cortex_post_build ( ${ PROJECT_NAME } ) If you are unfamiliar with cmake, please take a look at the guide An Introduction to Modern CMake . There are a few elements of the CMakeList.txt file which do not standard CMake: libhal::lpc4078 : Defines the specific package component for the the lpc4078 micro-controller. Using this component will automatically use the minimum required compiler and link flags for the microcontroller as well as use the standard linker script for the device. arm_cortex_post_build(${PROJECT_NAME}) : Provided by the toolchain file in the cmake-arm-embedded tool package. Generates the .hex (intel hex), .bin (binary), .S (disassembly) and .lst (disassembly with source interweaved). Writing main.cpp Read through the source code below to get an idea of whats needed: #include <libhal-armcortex/dwt_counter.hpp> #include <libhal-armcortex/startup.hpp> #include <libhal-armcortex/system_control.hpp> #include <libhal-lpc40/output_pin.hpp> #include <libhal-lpc40/system_controller.hpp> #include <libhal-util/steady_clock.hpp> int main () { using namespace hal :: literals ; using namespace std :: literals ; // Initializing the data section initializes global and static variables and // is required for the standard C library to run. hal :: cortex_m :: initialize_data_section (); hal :: cortex_m :: system_control :: initialize_floating_point_unit (); // Create a hardware counter auto & clock = hal :: lpc40xx :: clock :: get (); auto cpu_frequency = clock . get_frequency ( hal :: lpc40xx :: peripheral :: cpu ); static hal :: cortex_m :: dwt_counter steady_clock ( cpu_frequency ); // Get an output pin to use as the LED pin control auto & led_pin = hal :: lpc40xx :: output_pin :: get < 1 , 18 > (). value (); while ( true ) { ( void ) led_pin . level ( true ); ( void ) hal :: delay ( steady_clock , 500 ms ); ( void ) led_pin . level ( false ); ( void ) hal :: delay ( steady_clock , 500 ms ); } return 0 ; } // When libhal.tweaks.hpp includes: // // #define BOOST_LEAF_EMBEDDED // #define BOOST_LEAF_NO_THREADS // // Then Boost.LEAF needs this function to be defined namespace boost { void throw_exception ([[ maybe_unused ]] std :: exception const & p_error ) { std :: abort (); } } // namespace boost The newlib.cpp file The newlib.cpp contains low level APIs used by the standard C library. With an OS these are implemented with OS APIs. For example, the function that provides memory to malloc() is the newlib API sbrk() . To learn more about how to write newlib.cpp see From Zero to main(): Bootstrapping libc with Newlib . See libhal-starter/newlib.cpp for the default empty implementations. Compiling the project The command for building the project: conan build .","title":"\ud83c\udd95 Creating a new Project"},{"location":"how-to/project/#creating-a-new-project","text":"In this example we create a project using the CMake build system. In order to make a project you need 5 files: conanfile.txt : list of project dependencies. CMakeLists.txt : instructions describing the project's source files, executables and how to build them. main.cpp : application software libhal.tweaks.hpp : configuration file for libhal newlib.cpp : definitions of low level C functions","title":"\ud83c\udd95 Creating a new Project"},{"location":"how-to/project/#quick-start","text":"Clone this starter project: git clone https://github.com/libhal/libhal-starter.git","title":"Quick Start"},{"location":"how-to/project/#creating-the-conanfiletxt","text":"A standard libhal conanfile.txt will look like this: [requires] libhal-lpc40/1.1.6 [tool_requires] gnu-arm-embedded-toolchain/11.3.0 cmake-arm-embedded/0.1.1 [generators] CMakeToolchain CMakeDeps [requires] lists the project dependencies. Each libhal project needs a target library and this example uses libhal-lpc40 which is used for the SJ2 board or the LPC4078 micromod. [tool_requires] lists the tools that are needed to build the project. gnu-arm-embedded-toolchain/11.3.0 brings in the ARM GCC cross compiler which is used to compile to the code for ARM Cortex microcontroller. cmake-arm-embedded/0.1.1 brings in cmake helper scripts and toolchain files for configuring cmake for the cross compiler. [generators] list the generators which generate files for the project build systems. CMakeToolchain : Generates toolchain cmake scripts based on the conan package recipe information. CMakeDeps : Generates cmake package/configuration files for each library which can be","title":"Creating the conanfile.txt"},{"location":"how-to/project/#making-the-cmakeliststxt-file","text":"Below is the minimal amount of cmake code needed for a libhal project: cmake_minimum_required ( VERSION 3.20 ) project ( project_name.elf VERSION 0.0.1 LANGUAGES CXX ) find_package ( libhal-lpc40 REQUIRED CONFIG ) add_executable ( ${ PROJECT_NAME } main.cpp newlib.cpp ) target_compile_features ( ${ PROJECT_NAME } PRIVATE cxx_std_20 ) target_include_directories ( ${ PROJECT_NAME } PUBLIC . ) target_link_libraries ( ${ PROJECT_NAME } PRIVATE libhal::lpc4078 ) arm_cortex_post_build ( ${ PROJECT_NAME } ) If you are unfamiliar with cmake, please take a look at the guide An Introduction to Modern CMake . There are a few elements of the CMakeList.txt file which do not standard CMake: libhal::lpc4078 : Defines the specific package component for the the lpc4078 micro-controller. Using this component will automatically use the minimum required compiler and link flags for the microcontroller as well as use the standard linker script for the device. arm_cortex_post_build(${PROJECT_NAME}) : Provided by the toolchain file in the cmake-arm-embedded tool package. Generates the .hex (intel hex), .bin (binary), .S (disassembly) and .lst (disassembly with source interweaved).","title":"Making the CMakeLists.txt file"},{"location":"how-to/project/#writing-maincpp","text":"Read through the source code below to get an idea of whats needed: #include <libhal-armcortex/dwt_counter.hpp> #include <libhal-armcortex/startup.hpp> #include <libhal-armcortex/system_control.hpp> #include <libhal-lpc40/output_pin.hpp> #include <libhal-lpc40/system_controller.hpp> #include <libhal-util/steady_clock.hpp> int main () { using namespace hal :: literals ; using namespace std :: literals ; // Initializing the data section initializes global and static variables and // is required for the standard C library to run. hal :: cortex_m :: initialize_data_section (); hal :: cortex_m :: system_control :: initialize_floating_point_unit (); // Create a hardware counter auto & clock = hal :: lpc40xx :: clock :: get (); auto cpu_frequency = clock . get_frequency ( hal :: lpc40xx :: peripheral :: cpu ); static hal :: cortex_m :: dwt_counter steady_clock ( cpu_frequency ); // Get an output pin to use as the LED pin control auto & led_pin = hal :: lpc40xx :: output_pin :: get < 1 , 18 > (). value (); while ( true ) { ( void ) led_pin . level ( true ); ( void ) hal :: delay ( steady_clock , 500 ms ); ( void ) led_pin . level ( false ); ( void ) hal :: delay ( steady_clock , 500 ms ); } return 0 ; } // When libhal.tweaks.hpp includes: // // #define BOOST_LEAF_EMBEDDED // #define BOOST_LEAF_NO_THREADS // // Then Boost.LEAF needs this function to be defined namespace boost { void throw_exception ([[ maybe_unused ]] std :: exception const & p_error ) { std :: abort (); } } // namespace boost","title":"Writing main.cpp"},{"location":"how-to/project/#the-newlibcpp-file","text":"The newlib.cpp contains low level APIs used by the standard C library. With an OS these are implemented with OS APIs. For example, the function that provides memory to malloc() is the newlib API sbrk() . To learn more about how to write newlib.cpp see From Zero to main(): Bootstrapping libc with Newlib . See libhal-starter/newlib.cpp for the default empty implementations.","title":"The newlib.cpp file"},{"location":"how-to/project/#compiling-the-project","text":"The command for building the project: conan build .","title":"Compiling the project"},{"location":"how-to/utility/","text":"\ud83e\ude9b Utility Libraries Info Documentation coming soon...","title":"\ud83e\ude9b Utility Libraries"},{"location":"how-to/utility/#utility-libraries","text":"Info Documentation coming soon...","title":"\ud83e\ude9b Utility Libraries"},{"location":"interfaces/adc/","text":"adc interface design See ADC interface API for details on the interface and how to use it. Discussing read_t read_t only has a singular field and that is percentage . The reason a floating point number between -1.0 and 1.0 is to erase information like voltage and bit-resolution. Erasing Voltage The actual voltage on an ADC pin is not usually determinable by a ADC driver. The only thing an ADC peripheral can determine is the proportion of the read voltage relative to a voltage reference. That voltage reference could be anything, and therefore, there's no reason to try to embed that information into the ADC interface. Erasing Bit Resolution In general, analog to digital converters have a fixed bit resolution. In what cases would knowing the ADC resolution at runtime be useful? It wouldn't be useful in terms of calculating the voltage because you can use the floating point value for that. No, the only reason why a developer or driver would need the bit resolution to discriminate against an ADC, emitting an error that indicates that the resolution of an ADC is not high enough for the driver or application to work. But this would violate the D.4 Safe design philosophy that drivers should NOT hold code that attempts to check for problems of architecture.","title":"\u274c adc"},{"location":"interfaces/adc/#adc-interface-design","text":"See ADC interface API for details on the interface and how to use it.","title":"adc interface design"},{"location":"interfaces/adc/#discussing-read_t","text":"read_t only has a singular field and that is percentage . The reason a floating point number between -1.0 and 1.0 is to erase information like voltage and bit-resolution.","title":"Discussing read_t"},{"location":"interfaces/adc/#erasing-voltage","text":"The actual voltage on an ADC pin is not usually determinable by a ADC driver. The only thing an ADC peripheral can determine is the proportion of the read voltage relative to a voltage reference. That voltage reference could be anything, and therefore, there's no reason to try to embed that information into the ADC interface.","title":"Erasing Voltage"},{"location":"interfaces/adc/#erasing-bit-resolution","text":"In general, analog to digital converters have a fixed bit resolution. In what cases would knowing the ADC resolution at runtime be useful? It wouldn't be useful in terms of calculating the voltage because you can use the floating point value for that. No, the only reason why a developer or driver would need the bit resolution to discriminate against an ADC, emitting an error that indicates that the resolution of an ADC is not high enough for the driver or application to work. But this would violate the D.4 Safe design philosophy that drivers should NOT hold code that attempts to check for problems of architecture.","title":"Erasing Bit Resolution"},{"location":"interfaces/can/","text":"can interface design","title":"\u274c can"},{"location":"interfaces/can/#can-interface-design","text":"","title":"can interface design"},{"location":"interfaces/dac/","text":"dac interface design See DAC interface API for details on the interface and how to use it. dac is effectively the same design as ADC but as an output device and thus shares the same design rationale as ADC. See design/adc for details.","title":"\u2705 dac"},{"location":"interfaces/dac/#dac-interface-design","text":"See DAC interface API for details on the interface and how to use it. dac is effectively the same design as ADC but as an output device and thus shares the same design rationale as ADC. See design/adc for details.","title":"dac interface design"},{"location":"interfaces/i2c/","text":"i2c interface design See I2C interface API for details on the interface and how to use it. i2c::transaction() The singular transaction API can support all forms of standard i2c communication operations such as read, write, and write then read. It also comes with a timeout parameter which indicates to the i2c driver when a transaction should abort. Normally applications and drivers will use hal::never_timeout for parameter, unless an external device has the capability/need to perform clock stretching on the bus. The APIs for transaction were not split up into a separate read() , write() and write_then_read() functions in order to reduce vtable size to just two entries. Many i2c implementations incorporate all of these operations in the same algorithm or interrupt state machine which matches the current API structure. The separate operations can be made available using the i2c utility functions in libhal-util . i2c::configure() There is not much to say about configuration for i2c. There really is only one option that is variable with i2c an that is clock speed. Everything else is device and target specific.","title":"\u274c i2c"},{"location":"interfaces/i2c/#i2c-interface-design","text":"See I2C interface API for details on the interface and how to use it.","title":"i2c interface design"},{"location":"interfaces/i2c/#i2ctransaction","text":"The singular transaction API can support all forms of standard i2c communication operations such as read, write, and write then read. It also comes with a timeout parameter which indicates to the i2c driver when a transaction should abort. Normally applications and drivers will use hal::never_timeout for parameter, unless an external device has the capability/need to perform clock stretching on the bus. The APIs for transaction were not split up into a separate read() , write() and write_then_read() functions in order to reduce vtable size to just two entries. Many i2c implementations incorporate all of these operations in the same algorithm or interrupt state machine which matches the current API structure. The separate operations can be made available using the i2c utility functions in libhal-util .","title":"i2c::transaction()"},{"location":"interfaces/i2c/#i2cconfigure","text":"There is not much to say about configuration for i2c. There really is only one option that is variable with i2c an that is clock speed. Everything else is device and target specific.","title":"i2c::configure()"},{"location":"interfaces/input_pin/","text":"hal::input_pin Interface Tutorial In this tutorial, we'll learn about the hal::input_pin interface and how digital input pins work. This interface provides a hardware abstraction for digital input pins, making it easier to read the pin state and determine if the voltage on it is HIGH or LOW. What is a Digital Input Pin? A digital input pin is a pin on a microcontroller that reads the voltage level applied to it. The pin can read either a HIGH or a LOW voltage level. In most cases, a HIGH voltage level is represented by the supply voltage (e.g., 3.3V or 5V), while a LOW voltage level is represented by the ground (0V). Digital input pins are commonly used to read signals from sensors, buttons, and other external devices. Understanding the hal::input_pin Interface The hal::input_pin interface is designed to provide a consistent way to interact with digital input pins across various hardware platforms. It consists of a few key components: 1. settings Structure This structure holds the generic settings for input pins. It currently contains a single field, pin_resistor , which represents the pull resistor configuration for the input pin. The pull resistor can be set to pull_up or pull_down , depending on the hardware requirements. 2. level_t Structure The level_t structure is used to represent the measured state of the input pin. It has a single boolean field, state , which indicates whether the pin is at a HIGH voltage level ( true ) or a LOW voltage level ( false ). 3. configure Method This method is used to configure the input pin according to the supplied settings. It takes a settings object as an argument and returns a status object indicating success or failure. If the settings cannot be achieved, an std::errc::invalid_argument exception is thrown. 4. level Method The level method reads the state of the input pin and returns a result<level_t> object. A true value indicates a HIGH voltage level, while a false value indicates a LOW voltage level. 5. Virtual Driver Methods The driver_configure and driver_level methods are virtual and must be implemented by the derived class for specific hardware platforms. These methods are responsible for configuring the input pin and reading its level, respectively. Using the hal::input_pin Interface To use the hal::input_pin interface, you need to create a derived class that implements the virtual driver methods for your specific hardware platform. Here's a basic outline of how to do that: Include the input_pin.hpp header file in your project. Create a derived class that inherits from hal::input_pin . Implement the driver_configure and driver_level methods in your derived class. #include \"input_pin.hpp\" class my_input_pin : public hal :: input_pin { private : virtual hal :: status driver_configure ( const hal :: input_pin :: settings & p_settings ) override { // Implement hardware-specific configuration logic here } virtual hal :: result < hal :: input_pin :: level_t > driver_level () override { // Implement hardware-specific level reading logic here } }; Once you've created your derived class, you can use the configure and level methods to interact with the digital input pin. my_input_pin input_pin ; hal :: input_pin :: settings pin_settings ; pin_settings . resistor = hal :: pin_resistor :: pull_up ; auto configStatus = input_pin . configure ( pin_settings ); if ( configStatus == hal :: status :: success ) { // Successfully configured the input pin } else { // Handle configuration failure } // Read the state of the input pin auto pin_level_result = input_pin . level (); if ( pin_level_result ) { hal :: input_pin :: level_t pinLevel = pin_level_result . value (); if ( pinLevel . state ) { // The pin is at a HIGH voltage level } else { // The pin is at a LOW voltage level } } else { // Handle level reading failure } Digital Input Pin Tutorial Now that you understand the hal::input_pin interface, let's explore how digital input pins work in more detail. Digital input pins are used to read the voltage level applied to them. When a voltage level is applied to the pin, it compares the voltage to a threshold value to determine if the pin should read HIGH or LOW. This threshold is often set at around half of the supply voltage. When using digital input pins, it's essential to consider pull-up or pull-down resistors. These resistors help prevent undefined behavior caused by floating pins. A floating pin is a pin that is not connected to a HIGH or LOW voltage source and can pick up noise, resulting in unpredictable behavior. Pull-Up Resistor A pull-up resistor connects the digital input pin to the supply voltage (Vcc) through a resistor. When no external voltage is applied to the pin, the pull-up resistor pulls the voltage level to Vcc, causing the pin to read HIGH. When an external device connects the pin to ground (GND), the pin reads LOW. Pull-Down Resistor A pull-down resistor connects the digital input pin to ground (GND) through a resistor. When no external voltage is applied to the pin, the pull-down resistor pulls the voltage level to GND, causing the pin to read LOW. When an external device connects the pin to the supply voltage (Vcc), the pin reads HIGH. It's important to choose the appropriate pull resistor configuration based on your specific hardware and application requirements. The hal::input_pin::settings structure in the hal::input_pin interface allows you to specify the pull resistor configuration for your input pin. To use the hal::input_pin interface with the appropriate pull resistor configuration, create a derived class as described earlier in the tutorial. In the driver_configure method implementation, configure your hardware platform to use the specified pull resistor settings. Then, use the configure and level methods provided by the hal::input_pin interface to interact with the digital input pin and read its state.","title":"\u274c input_pin"},{"location":"interfaces/input_pin/#halinput_pin-interface-tutorial","text":"In this tutorial, we'll learn about the hal::input_pin interface and how digital input pins work. This interface provides a hardware abstraction for digital input pins, making it easier to read the pin state and determine if the voltage on it is HIGH or LOW.","title":"hal::input_pin Interface Tutorial"},{"location":"interfaces/input_pin/#what-is-a-digital-input-pin","text":"A digital input pin is a pin on a microcontroller that reads the voltage level applied to it. The pin can read either a HIGH or a LOW voltage level. In most cases, a HIGH voltage level is represented by the supply voltage (e.g., 3.3V or 5V), while a LOW voltage level is represented by the ground (0V). Digital input pins are commonly used to read signals from sensors, buttons, and other external devices.","title":"What is a Digital Input Pin?"},{"location":"interfaces/input_pin/#understanding-the-halinput_pin-interface","text":"The hal::input_pin interface is designed to provide a consistent way to interact with digital input pins across various hardware platforms. It consists of a few key components:","title":"Understanding the hal::input_pin Interface"},{"location":"interfaces/input_pin/#1-settings-structure","text":"This structure holds the generic settings for input pins. It currently contains a single field, pin_resistor , which represents the pull resistor configuration for the input pin. The pull resistor can be set to pull_up or pull_down , depending on the hardware requirements.","title":"1. settings Structure"},{"location":"interfaces/input_pin/#2-level_t-structure","text":"The level_t structure is used to represent the measured state of the input pin. It has a single boolean field, state , which indicates whether the pin is at a HIGH voltage level ( true ) or a LOW voltage level ( false ).","title":"2. level_t Structure"},{"location":"interfaces/input_pin/#3-configure-method","text":"This method is used to configure the input pin according to the supplied settings. It takes a settings object as an argument and returns a status object indicating success or failure. If the settings cannot be achieved, an std::errc::invalid_argument exception is thrown.","title":"3. configure Method"},{"location":"interfaces/input_pin/#4-level-method","text":"The level method reads the state of the input pin and returns a result<level_t> object. A true value indicates a HIGH voltage level, while a false value indicates a LOW voltage level.","title":"4. level Method"},{"location":"interfaces/input_pin/#5-virtual-driver-methods","text":"The driver_configure and driver_level methods are virtual and must be implemented by the derived class for specific hardware platforms. These methods are responsible for configuring the input pin and reading its level, respectively.","title":"5. Virtual Driver Methods"},{"location":"interfaces/input_pin/#using-the-halinput_pin-interface","text":"To use the hal::input_pin interface, you need to create a derived class that implements the virtual driver methods for your specific hardware platform. Here's a basic outline of how to do that: Include the input_pin.hpp header file in your project. Create a derived class that inherits from hal::input_pin . Implement the driver_configure and driver_level methods in your derived class. #include \"input_pin.hpp\" class my_input_pin : public hal :: input_pin { private : virtual hal :: status driver_configure ( const hal :: input_pin :: settings & p_settings ) override { // Implement hardware-specific configuration logic here } virtual hal :: result < hal :: input_pin :: level_t > driver_level () override { // Implement hardware-specific level reading logic here } }; Once you've created your derived class, you can use the configure and level methods to interact with the digital input pin. my_input_pin input_pin ; hal :: input_pin :: settings pin_settings ; pin_settings . resistor = hal :: pin_resistor :: pull_up ; auto configStatus = input_pin . configure ( pin_settings ); if ( configStatus == hal :: status :: success ) { // Successfully configured the input pin } else { // Handle configuration failure } // Read the state of the input pin auto pin_level_result = input_pin . level (); if ( pin_level_result ) { hal :: input_pin :: level_t pinLevel = pin_level_result . value (); if ( pinLevel . state ) { // The pin is at a HIGH voltage level } else { // The pin is at a LOW voltage level } } else { // Handle level reading failure }","title":"Using the hal::input_pin Interface"},{"location":"interfaces/input_pin/#digital-input-pin-tutorial","text":"Now that you understand the hal::input_pin interface, let's explore how digital input pins work in more detail. Digital input pins are used to read the voltage level applied to them. When a voltage level is applied to the pin, it compares the voltage to a threshold value to determine if the pin should read HIGH or LOW. This threshold is often set at around half of the supply voltage. When using digital input pins, it's essential to consider pull-up or pull-down resistors. These resistors help prevent undefined behavior caused by floating pins. A floating pin is a pin that is not connected to a HIGH or LOW voltage source and can pick up noise, resulting in unpredictable behavior.","title":"Digital Input Pin Tutorial"},{"location":"interfaces/input_pin/#pull-up-resistor","text":"A pull-up resistor connects the digital input pin to the supply voltage (Vcc) through a resistor. When no external voltage is applied to the pin, the pull-up resistor pulls the voltage level to Vcc, causing the pin to read HIGH. When an external device connects the pin to ground (GND), the pin reads LOW.","title":"Pull-Up Resistor"},{"location":"interfaces/input_pin/#pull-down-resistor","text":"A pull-down resistor connects the digital input pin to ground (GND) through a resistor. When no external voltage is applied to the pin, the pull-down resistor pulls the voltage level to GND, causing the pin to read LOW. When an external device connects the pin to the supply voltage (Vcc), the pin reads HIGH. It's important to choose the appropriate pull resistor configuration based on your specific hardware and application requirements. The hal::input_pin::settings structure in the hal::input_pin interface allows you to specify the pull resistor configuration for your input pin. To use the hal::input_pin interface with the appropriate pull resistor configuration, create a derived class as described earlier in the tutorial. In the driver_configure method implementation, configure your hardware platform to use the specified pull resistor settings. Then, use the configure and level methods provided by the hal::input_pin interface to interact with the digital input pin and read its state.","title":"Pull-Down Resistor"},{"location":"interfaces/interrupt_pin/","text":"interrupt_pin interface design","title":"\u274c interrupt_pin"},{"location":"interfaces/interrupt_pin/#interrupt_pin-interface-design","text":"","title":"interrupt_pin interface design"},{"location":"interfaces/motor/","text":"motor interface design","title":"\u274c motor"},{"location":"interfaces/motor/#motor-interface-design","text":"","title":"motor interface design"},{"location":"interfaces/output_pin/","text":"output_pin interface design","title":"\u274c output_pin"},{"location":"interfaces/output_pin/#output_pin-interface-design","text":"","title":"output_pin interface design"},{"location":"interfaces/pwm/","text":"pwm interface design A basic PWM should have the capability to control frequency and duty cycle.","title":"\u274c pwm"},{"location":"interfaces/pwm/#pwm-interface-design","text":"A basic PWM should have the capability to control frequency and duty cycle.","title":"pwm interface design"},{"location":"interfaces/serial/","text":"serial interface design","title":"\u274c serial"},{"location":"interfaces/serial/#serial-interface-design","text":"","title":"serial interface design"},{"location":"interfaces/servo/","text":"servo interface design","title":"\u274c servo"},{"location":"interfaces/servo/#servo-interface-design","text":"","title":"servo interface design"},{"location":"interfaces/socket/","text":"socket interface design","title":"\u274c socket"},{"location":"interfaces/socket/#socket-interface-design","text":"","title":"socket interface design"},{"location":"interfaces/spi/","text":"spi interface design See SPI interface API for details on the interface and how to use it. Supporting just 8-bit frames 8-bit frames are the most common frame size for SPI. 16-bit does work, but this can be achieved with two 8-bit frames of data. Other frame sizes are very rare and thus does not warrant the complexity added to the interface, hal::spi::settings_t object, and hal::spi::configure function. If additional frame sizes are needed, then a new hal::variable_frame_spi interface would be created. In the case the hal::variable_frame_spi , you pay for the cost of a more complex implementation. Not including chip select The spi interface gives no control over a chip select pin. There are two reasons for this: Most SPI peripherals have a single NSS or CS pin per SPI bus. If the user wants to talk to multiple devices on that bus, then the application will need to disable that pin and use separate output pins to select the appropriate device. Thus the CS pin is useless in this situation. The behavior of a chip select pin is device specific and may not match how the peripheral controls the chip select. Drivers must have complete control over the chip select pin and how it used, thus that control cannot be given to the SPI peripheral. Because of these two factors SPI driver are decoupled from their respective chip select pin. Thus ever device driver that accepts a hal::spi must also accept a chip select pin, unless the device does not have an chip select pin and must exist on the bus all by itself.","title":"\u274c spi"},{"location":"interfaces/spi/#spi-interface-design","text":"See SPI interface API for details on the interface and how to use it.","title":"spi interface design"},{"location":"interfaces/spi/#supporting-just-8-bit-frames","text":"8-bit frames are the most common frame size for SPI. 16-bit does work, but this can be achieved with two 8-bit frames of data. Other frame sizes are very rare and thus does not warrant the complexity added to the interface, hal::spi::settings_t object, and hal::spi::configure function. If additional frame sizes are needed, then a new hal::variable_frame_spi interface would be created. In the case the hal::variable_frame_spi , you pay for the cost of a more complex implementation.","title":"Supporting just 8-bit frames"},{"location":"interfaces/spi/#not-including-chip-select","text":"The spi interface gives no control over a chip select pin. There are two reasons for this: Most SPI peripherals have a single NSS or CS pin per SPI bus. If the user wants to talk to multiple devices on that bus, then the application will need to disable that pin and use separate output pins to select the appropriate device. Thus the CS pin is useless in this situation. The behavior of a chip select pin is device specific and may not match how the peripheral controls the chip select. Drivers must have complete control over the chip select pin and how it used, thus that control cannot be given to the SPI peripheral. Because of these two factors SPI driver are decoupled from their respective chip select pin. Thus ever device driver that accepts a hal::spi must also accept a chip select pin, unless the device does not have an chip select pin and must exist on the bus all by itself.","title":"Not including chip select"},{"location":"interfaces/steady_clock/","text":"steady_clock interface design","title":"\u274c steady_clock"},{"location":"interfaces/steady_clock/#steady_clock-interface-design","text":"","title":"steady_clock interface design"},{"location":"interfaces/timer/","text":"timer interface design","title":"\u274c timer"},{"location":"interfaces/timer/#timer-interface-design","text":"","title":"timer interface design"},{"location":"tutorials/building_blocks/","text":"\ud83e\uddf1 Interface Building Blocks hal::result<T> & hal::status hal::result<T> is an alias for the boost::leaf::result<T> type. This type can either be the value T or an error. The type is not a variant but can be considered closer to a std::pair<T, bool> . It holds both and the bool indicates if the object is an error or not. No errors are held in the status structure. The error data is either dropped or saved to the variable within the handler statement within a hal::attempt block (which is an alias for boost::leaf::try_handle_some ). hal::status is simply a concise alias for the type boost::leaf::result<void> . See Boost.LEAF for more details about it and how it works. The main reasons why Boost.LEAF was used can be found in Architecture: Boost.LEAF for error handling . HAL_CHECK() HAL_CHECK() is a macro that takes an expression that evaluates to a hal::result<T> or hal::status . HAL_CHECK() either returns from the calling function if an error was emitted as a result of evaluating the expression or in the case of hal::result<T> , HAL_CHECK() returns the value T . For example: // HAL_CHECK unwraps the hal::result<T> type and returns it if it was successful // or returns from the calling function with an error result. hal :: adc :: read_t adc_reading = HAL_CHECK ( adc . read ()); libhal/units.hpp This file contains the definition of the common base units used in libhal as well UDL (user defined literals) that help to make unit conversions easier. Although most of the units are simply floats, giving them names in the APIs helps with clarity and readability. hal::timeout concept A timeout in libhal is a \"callable\" that takes no arguments and returns a hal::status as such using timeout = hal::status(void) as defined in libhal/timeout.hpp . A \"callable\" is something that can be called such as function, functor, lambda, etc. The purpose of hal::timeout is to indicate when an operation has run out of time. hal::timeout will emit a std::errc::timed_out value if it timed out. Because it returns a hal::status it can also emit other errors. The other errors should be passed up the stack rather than handled by the operation. And because of this, if a hal::timeout ever emits something other than a std::errc::timed_out , then the operation stops and the error is bubbled up to the appropriate handler. Timeout callable objects are used rather than a time duration because the source of an timeout may not be time based but based on an interrupt signal from another system. Using a time duration for a timeout means that the system would either need (and have to manage) a global clock or take a singular clock like source at construction time. Using this gives the most flexibility to the user.","title":"\ud83e\uddf1 Interface Building Blocks"},{"location":"tutorials/building_blocks/#interface-building-blocks","text":"","title":"\ud83e\uddf1 Interface Building Blocks"},{"location":"tutorials/building_blocks/#halresultt-halstatus","text":"hal::result<T> is an alias for the boost::leaf::result<T> type. This type can either be the value T or an error. The type is not a variant but can be considered closer to a std::pair<T, bool> . It holds both and the bool indicates if the object is an error or not. No errors are held in the status structure. The error data is either dropped or saved to the variable within the handler statement within a hal::attempt block (which is an alias for boost::leaf::try_handle_some ). hal::status is simply a concise alias for the type boost::leaf::result<void> . See Boost.LEAF for more details about it and how it works. The main reasons why Boost.LEAF was used can be found in Architecture: Boost.LEAF for error handling .","title":"hal::result&lt;T&gt; &amp; hal::status"},{"location":"tutorials/building_blocks/#hal_check","text":"HAL_CHECK() is a macro that takes an expression that evaluates to a hal::result<T> or hal::status . HAL_CHECK() either returns from the calling function if an error was emitted as a result of evaluating the expression or in the case of hal::result<T> , HAL_CHECK() returns the value T . For example: // HAL_CHECK unwraps the hal::result<T> type and returns it if it was successful // or returns from the calling function with an error result. hal :: adc :: read_t adc_reading = HAL_CHECK ( adc . read ());","title":"HAL_CHECK()"},{"location":"tutorials/building_blocks/#libhalunitshpp","text":"This file contains the definition of the common base units used in libhal as well UDL (user defined literals) that help to make unit conversions easier. Although most of the units are simply floats, giving them names in the APIs helps with clarity and readability.","title":"libhal/units.hpp"},{"location":"tutorials/building_blocks/#haltimeout-concept","text":"A timeout in libhal is a \"callable\" that takes no arguments and returns a hal::status as such using timeout = hal::status(void) as defined in libhal/timeout.hpp . A \"callable\" is something that can be called such as function, functor, lambda, etc. The purpose of hal::timeout is to indicate when an operation has run out of time. hal::timeout will emit a std::errc::timed_out value if it timed out. Because it returns a hal::status it can also emit other errors. The other errors should be passed up the stack rather than handled by the operation. And because of this, if a hal::timeout ever emits something other than a std::errc::timed_out , then the operation stops and the error is bubbled up to the appropriate handler. Timeout callable objects are used rather than a time duration because the source of an timeout may not be time based but based on an interrupt signal from another system. Using a time duration for a timeout means that the system would either need (and have to manage) a global clock or take a singular clock like source at construction time. Using this gives the most flexibility to the user.","title":"hal::timeout concept"},{"location":"tutorials/configuration/","text":"\ud83c\udf9a\ufe0f Configuration libhal is very lightweight and thus has very few knobs that can be configured. The few that it does have are critical to get right. libhal uses tweak.hpp header files for customization and configuration. See A New Approach to Build-Time Library Configuration for more details. Below is an example libhal.tweaks.hpp file with all 3 fields set to their defaults: #pragma once #include <string_view> namespace hal :: config { constexpr std :: string_view platform = \"undefined\" ; constexpr bool on_error_callback_enabled = false ; constexpr auto on_error_callback = []() {}; } // namespace hal::config Create a libhal.tweaks.hpp file somewhere in your application and make sure it is within one of the compiler's include paths. For GCC/Clang you can use the -I flag to specify the directory where headers can be found. The file must be at the root of the directory listed within the -I include path. There can only be one libhal.tweaks.hpp per application build. Error Not providing a libhal.tweaks.hpp file will result in a compiler error by libhal. platform Note Currently this flag is mislabelled as platform and should be labeled as target . Set the string to the name of the device you are working with. Information about what the target string should be set to can be found in the target's libhal library README.md. Lets consider we are using the STM32 Blue Pill Board . The microcontroller on that board is the stm32f103c8t6 and thus the target name should be stm32f103c8t6 . Drivers will use parts of the target string to configure their behavior such as using generating a compile time error if a peripheral is used with an unsupported target. Using a shorter target name, such as stm32f10 will work as well. What this tells the drivers is that you want this project to work on any generic STM32F10x series chip. This will limit which drivers the application can use to the ones common across all STM32F10x series chips can support. A special target name is test which is used to indicate to driver to configure themselves for unit testing. This generally means that memory mapped peripherals will allocate their registers in ram rather than attempting to access them via their peripheral address, which wouldn't make sense on a host machine as their memory maps are different. on_error_callback_enable on_error_callback_enabled enables the usage of the on_error_callback . on_error_callback on_error_callback specifies a callback that should be called when any errors occur. The main purpose of this is to capture a stack trace when errors occur but can be used for anything. Info The callback is called before the error has been constructed and transported Tip Prefer to use an extern function defined above the libhal::config namespace and define the function elsewhere. This prevents issues with inclusion order issues with libhal.tweaks.hpp which occur because ALL libhal interfaces include <libhal/config.hpp> which directly includes libhal.tweaks.hpp which WILL result in an circular inclusion error/issue. Here is an example below: #pragma once #include <string_view> namespace my_project :: config { extern void my_error_handler (); } namespace hal :: config { constexpr std :: string_view platform = \"undefined\" ; constexpr bool on_error_callback_enabled = false ; constexpr auto on_error_callback = []() { my_project :: config :: my_error_handler (); }; } // namespace hal::config","title":"\ud83c\udf9a\ufe0f Configuration"},{"location":"tutorials/configuration/#configuration","text":"libhal is very lightweight and thus has very few knobs that can be configured. The few that it does have are critical to get right. libhal uses tweak.hpp header files for customization and configuration. See A New Approach to Build-Time Library Configuration for more details. Below is an example libhal.tweaks.hpp file with all 3 fields set to their defaults: #pragma once #include <string_view> namespace hal :: config { constexpr std :: string_view platform = \"undefined\" ; constexpr bool on_error_callback_enabled = false ; constexpr auto on_error_callback = []() {}; } // namespace hal::config Create a libhal.tweaks.hpp file somewhere in your application and make sure it is within one of the compiler's include paths. For GCC/Clang you can use the -I flag to specify the directory where headers can be found. The file must be at the root of the directory listed within the -I include path. There can only be one libhal.tweaks.hpp per application build. Error Not providing a libhal.tweaks.hpp file will result in a compiler error by libhal.","title":"\ud83c\udf9a\ufe0f Configuration"},{"location":"tutorials/configuration/#platform","text":"Note Currently this flag is mislabelled as platform and should be labeled as target . Set the string to the name of the device you are working with. Information about what the target string should be set to can be found in the target's libhal library README.md. Lets consider we are using the STM32 Blue Pill Board . The microcontroller on that board is the stm32f103c8t6 and thus the target name should be stm32f103c8t6 . Drivers will use parts of the target string to configure their behavior such as using generating a compile time error if a peripheral is used with an unsupported target. Using a shorter target name, such as stm32f10 will work as well. What this tells the drivers is that you want this project to work on any generic STM32F10x series chip. This will limit which drivers the application can use to the ones common across all STM32F10x series chips can support. A special target name is test which is used to indicate to driver to configure themselves for unit testing. This generally means that memory mapped peripherals will allocate their registers in ram rather than attempting to access them via their peripheral address, which wouldn't make sense on a host machine as their memory maps are different.","title":"platform"},{"location":"tutorials/configuration/#on_error_callback_enable","text":"on_error_callback_enabled enables the usage of the on_error_callback .","title":"on_error_callback_enable"},{"location":"tutorials/configuration/#on_error_callback","text":"on_error_callback specifies a callback that should be called when any errors occur. The main purpose of this is to capture a stack trace when errors occur but can be used for anything. Info The callback is called before the error has been constructed and transported Tip Prefer to use an extern function defined above the libhal::config namespace and define the function elsewhere. This prevents issues with inclusion order issues with libhal.tweaks.hpp which occur because ALL libhal interfaces include <libhal/config.hpp> which directly includes libhal.tweaks.hpp which WILL result in an circular inclusion error/issue. Here is an example below: #pragma once #include <string_view> namespace my_project :: config { extern void my_error_handler (); } namespace hal :: config { constexpr std :: string_view platform = \"undefined\" ; constexpr bool on_error_callback_enabled = false ; constexpr auto on_error_callback = []() { my_project :: config :: my_error_handler (); }; } // namespace hal::config","title":"on_error_callback"},{"location":"tutorials/debugging/","text":"\ud83d\udd0e On Chip Software Debugging \ud83d\udfe1 JTAG and SWD debuggers are the standard ways to interact with microcontrollers in order to halt their actions, inspect memory, and step through code. It can be used to flash devices, which can sometimes be faster than doing so over serial. Can be used to perform on device line-by-line code debugging which is a powerful tool over print statements when it comes to debugging the state and behavior of a program. This tutorial uses PyOCD because its easy to use, and easy to install. The other big OCD (on-chip debugging) software is OpenOCD which works as well but is a bit more complicated to use. One issue with PyOCD is that it only works for ARM processors, so it cannot be used for RISC-V, MIPS, XTensa based devices. To install PyOCD run: python3 -m pip install pyocd Connecting to a Debugger Connect the debugger (STLinkV2) to your MicroMod Carrier board using the STLink to SWD connector adapter. Before connecting and powering everything check that the the ribbon connector is connected to the port with the glowing LED. That is the correct connection. Using the incorrect connection could cause part damage. If you are using another type of device with different connections follow this guide. A connection to ground ( GND ) must be made between the debugger and the development board in order for the devices to communicate. Danger DOUBLE AND TRIPLE CHECK YOUR CONNECTIONS! Incorrect connects can result in breaking a board, debugger or possible your computer. Connecting SWD Connecting JTAG Connect jumpers from GND , SWDIO and SWDCLK to the pins on the board. If the board supports both SWD and JTAG like many arm cortex boards do, then connect the pins in the following way: SWDIO --> TMS SWDCLK --> TCK Connect jumpers from the GND , TDI , TMS , TCK , and TDO pins on the JTAG debugger to the headers on the development board of the same name. Using GDB If you do not know how to use GDB here is a GDB Cheat Sheet . You should be able to add breakpoints to add breakpoints at this point. A typical first breakpoint for a program is to set a breakpoint on main. >>> break main Next you will want to reset the program back to the start and halt the CPU using the following command. >>> monitor reset halt To begin running through the program use the continue command. >>> continue At this point you should see the source code of your main.cpp show up. Now you can step through your code and set breakpoints using step , next , finish and continue , break , etc. Typically you would use the run command to start the code. When performing firmware testing, the run command is not needed as the code is already \"running\" on the remote microcontroller. Info On boards with a factory bootloader, when you start debugging, you will notice that you cannot see the source code lines in the gdb shell. This is because the bootloader instructions are not associated with any addresses in your code, thus you will not see source code. This is fine. Continue with the guide. The LPC40xx family of microcontrollers has such a bootloader. Tip Highly recommend using tui enable or gdb-dashboard which is an awesome tool for making command line gdb debugging easier. Using print and set variable commands A very helpful command for GDB is the print command. >>> print a + 123 The statement above takes any expression and will print its result. For example one could do something like this: >>> print reg.TIM1.CCER The above expression will print the TIMER1 CCER register value. Tip If you get an error like: Cannot access memory at address ??? This happens because GDB is limiting access to memory that is known at link time and is apart of the binary's structure. But if a user wants to access peripheral memory not associated with RAM or Flash memory then they can execute this command: set mem inaccessible-by-default off You can also use the set variable command to actually change those values. For example, if you are within a loop you force the loop i iterator variable to 5. You can also change register values as well. >>> set variable i = 5 >>> set variable reg.USART1.CR1 = 1","title":"\ud83d\udd0e On Chip Software Debugging \ud83d\udfe1"},{"location":"tutorials/debugging/#on-chip-software-debugging","text":"JTAG and SWD debuggers are the standard ways to interact with microcontrollers in order to halt their actions, inspect memory, and step through code. It can be used to flash devices, which can sometimes be faster than doing so over serial. Can be used to perform on device line-by-line code debugging which is a powerful tool over print statements when it comes to debugging the state and behavior of a program. This tutorial uses PyOCD because its easy to use, and easy to install. The other big OCD (on-chip debugging) software is OpenOCD which works as well but is a bit more complicated to use. One issue with PyOCD is that it only works for ARM processors, so it cannot be used for RISC-V, MIPS, XTensa based devices. To install PyOCD run: python3 -m pip install pyocd","title":"\ud83d\udd0e On Chip Software Debugging \ud83d\udfe1"},{"location":"tutorials/debugging/#connecting-to-a-debugger","text":"Connect the debugger (STLinkV2) to your MicroMod Carrier board using the STLink to SWD connector adapter. Before connecting and powering everything check that the the ribbon connector is connected to the port with the glowing LED. That is the correct connection. Using the incorrect connection could cause part damage. If you are using another type of device with different connections follow this guide. A connection to ground ( GND ) must be made between the debugger and the development board in order for the devices to communicate. Danger DOUBLE AND TRIPLE CHECK YOUR CONNECTIONS! Incorrect connects can result in breaking a board, debugger or possible your computer. Connecting SWD Connecting JTAG Connect jumpers from GND , SWDIO and SWDCLK to the pins on the board. If the board supports both SWD and JTAG like many arm cortex boards do, then connect the pins in the following way: SWDIO --> TMS SWDCLK --> TCK Connect jumpers from the GND , TDI , TMS , TCK , and TDO pins on the JTAG debugger to the headers on the development board of the same name.","title":"Connecting to a Debugger"},{"location":"tutorials/debugging/#using-gdb","text":"If you do not know how to use GDB here is a GDB Cheat Sheet . You should be able to add breakpoints to add breakpoints at this point. A typical first breakpoint for a program is to set a breakpoint on main. >>> break main Next you will want to reset the program back to the start and halt the CPU using the following command. >>> monitor reset halt To begin running through the program use the continue command. >>> continue At this point you should see the source code of your main.cpp show up. Now you can step through your code and set breakpoints using step , next , finish and continue , break , etc. Typically you would use the run command to start the code. When performing firmware testing, the run command is not needed as the code is already \"running\" on the remote microcontroller. Info On boards with a factory bootloader, when you start debugging, you will notice that you cannot see the source code lines in the gdb shell. This is because the bootloader instructions are not associated with any addresses in your code, thus you will not see source code. This is fine. Continue with the guide. The LPC40xx family of microcontrollers has such a bootloader. Tip Highly recommend using tui enable or gdb-dashboard which is an awesome tool for making command line gdb debugging easier.","title":"Using GDB"},{"location":"tutorials/debugging/#using-print-and-set-variable-commands","text":"A very helpful command for GDB is the print command. >>> print a + 123 The statement above takes any expression and will print its result. For example one could do something like this: >>> print reg.TIM1.CCER The above expression will print the TIMER1 CCER register value. Tip If you get an error like: Cannot access memory at address ??? This happens because GDB is limiting access to memory that is known at link time and is apart of the binary's structure. But if a user wants to access peripheral memory not associated with RAM or Flash memory then they can execute this command: set mem inaccessible-by-default off You can also use the set variable command to actually change those values. For example, if you are within a loop you force the loop i iterator variable to 5. You can also change register values as well. >>> set variable i = 5 >>> set variable reg.USART1.CR1 = 1","title":"Using print and set variable commands"},{"location":"tutorials/error_handling/","text":"\ud83e\udea4 Error Handling \ud83d\udfe1","title":"\ud83e\udea4 Error Handling \ud83d\udfe1"},{"location":"tutorials/error_handling/#error-handling","text":"","title":"\ud83e\udea4 Error Handling \ud83d\udfe1"},{"location":"tutorials/organization/","text":"\ud83d\uddc3\ufe0f Organization This section will explain the different parts/repos of libhal organization and ecosystem and how they are organized. Target Libraries Target libraries depend on processor/OS libraries. The target libraries will include drivers for peripherals contained within their chip packages or, in the case of development boards and SBC (single board computers), these can also contain drivers external to the main chip. Processor/OS libraries contain APIs specific to those platforms for doing such things as handling interrupt service routines, initializing memory and more. flowchart LR libhal subgraph processor/OS libriscvmcu libarmcortex libhal-linux end subgraph arm-targets liblpc40xx libstm32f10x end subgraph riscv-targets libgv32f10x libsifive end subgraph linux-targets libhal-linux-generic libraspi end libhal-->libhal-linux libhal-->libriscvmcu libhal-->libarmcortex libarmcortex-->liblpc40xx libarmcortex-->libstm32f10x libriscvmcu-->libgv32f10x libriscvmcu-->libsifive libhal-linux-->libhal-linux-generic libhal-linux-->libraspi Device Libraries Device driver libraries have a very simple relationship tree. Device libraries just need the libhal interfaces to work. The implementations of those interfaces will come from a target library in the application. flowchart TD libhal libhal-->libhal-soft libhal-->libmpu libhal-->libesp8266 libhal-->libdrv libhal-->libwii libhal-->liballegro-micro libhal-->libdisplay-ssd libhal-->libled-apa-sk libhal-->libmatrix Typical Application Lets consider an application such as \"Pong\". A game of pong where we use an LED matrix and two Wii controllers using the STM32F103 microcontroller. flowchart LR libhal-->libmatrix-->app libhal-->libarmcortex-->libstm32f10x -->app libhal-->libwii-->app The conanfile.txt would look something like this: [requires] libstm32f10x/1.1.0 libmatrix/1.0.2 libwii/1.5.2 [generators] CMakeToolchain CMakeDeps VirtualRunEnv Application Libraries Application libraries are effectively applications with no specific dependency on a particular target. The point of a Application library is to deploy a fully fledged application, but with customizable drivers. For example, the pong game mentioned earlier doesn't require a wii controller or a LED matrix specifically. You could take a hal::display interface (not currently available) and some pong::gamepad interface defined by the Application library that the developer can implement themselves. Then the pong Application can take your display, gamepad and additional information like, \"paddle size\" and \"font size\" and use it to generate a game of pong. The developer gets the opportunity to choose which parts they want for each. Maybe they want a very large TFT display or they want to use a LED matrix. Maybe they want to use a Stadia controller or maybe they want to make a controller out of capacitive sensors and bananas. The choices are endless. \ud83d\udd0d Finding Drivers To find drivers you can look in three locations libhal organization conan center index libhal driver index \u274c Example libhal driver index is not available currently and is key to finding drivers around the ecosystem. Search for the name of the device or target you are interested with with the prefix lib in front of it. Try not to be too specific though. For example, the stm32f103c8t6 microcontroller target library drivers will be in the package libstm32f10x . The mpu6050 accelerometer will be in libmpu . \ud83d\udcd1 Reference Material Reference material can be found in the datasheets/ and schematic/ folders. The layout of these directories match that demos/ , where the first layer of folders are named after the microcontroller or board they describe. These folders are updated with relevant documents for easy access for our developers and contributors.","title":"\ud83d\uddc3\ufe0f Organization"},{"location":"tutorials/organization/#organization","text":"This section will explain the different parts/repos of libhal organization and ecosystem and how they are organized.","title":"\ud83d\uddc3\ufe0f Organization"},{"location":"tutorials/organization/#target-libraries","text":"Target libraries depend on processor/OS libraries. The target libraries will include drivers for peripherals contained within their chip packages or, in the case of development boards and SBC (single board computers), these can also contain drivers external to the main chip. Processor/OS libraries contain APIs specific to those platforms for doing such things as handling interrupt service routines, initializing memory and more. flowchart LR libhal subgraph processor/OS libriscvmcu libarmcortex libhal-linux end subgraph arm-targets liblpc40xx libstm32f10x end subgraph riscv-targets libgv32f10x libsifive end subgraph linux-targets libhal-linux-generic libraspi end libhal-->libhal-linux libhal-->libriscvmcu libhal-->libarmcortex libarmcortex-->liblpc40xx libarmcortex-->libstm32f10x libriscvmcu-->libgv32f10x libriscvmcu-->libsifive libhal-linux-->libhal-linux-generic libhal-linux-->libraspi","title":"Target Libraries"},{"location":"tutorials/organization/#device-libraries","text":"Device driver libraries have a very simple relationship tree. Device libraries just need the libhal interfaces to work. The implementations of those interfaces will come from a target library in the application. flowchart TD libhal libhal-->libhal-soft libhal-->libmpu libhal-->libesp8266 libhal-->libdrv libhal-->libwii libhal-->liballegro-micro libhal-->libdisplay-ssd libhal-->libled-apa-sk libhal-->libmatrix","title":"Device Libraries"},{"location":"tutorials/organization/#typical-application","text":"Lets consider an application such as \"Pong\". A game of pong where we use an LED matrix and two Wii controllers using the STM32F103 microcontroller. flowchart LR libhal-->libmatrix-->app libhal-->libarmcortex-->libstm32f10x -->app libhal-->libwii-->app The conanfile.txt would look something like this: [requires] libstm32f10x/1.1.0 libmatrix/1.0.2 libwii/1.5.2 [generators] CMakeToolchain CMakeDeps VirtualRunEnv","title":"Typical Application"},{"location":"tutorials/organization/#application-libraries","text":"Application libraries are effectively applications with no specific dependency on a particular target. The point of a Application library is to deploy a fully fledged application, but with customizable drivers. For example, the pong game mentioned earlier doesn't require a wii controller or a LED matrix specifically. You could take a hal::display interface (not currently available) and some pong::gamepad interface defined by the Application library that the developer can implement themselves. Then the pong Application can take your display, gamepad and additional information like, \"paddle size\" and \"font size\" and use it to generate a game of pong. The developer gets the opportunity to choose which parts they want for each. Maybe they want a very large TFT display or they want to use a LED matrix. Maybe they want to use a Stadia controller or maybe they want to make a controller out of capacitive sensors and bananas. The choices are endless.","title":"Application Libraries"},{"location":"tutorials/organization/#finding-drivers","text":"To find drivers you can look in three locations libhal organization conan center index libhal driver index \u274c Example libhal driver index is not available currently and is key to finding drivers around the ecosystem. Search for the name of the device or target you are interested with with the prefix lib in front of it. Try not to be too specific though. For example, the stm32f103c8t6 microcontroller target library drivers will be in the package libstm32f10x . The mpu6050 accelerometer will be in libmpu .","title":"\ud83d\udd0d Finding Drivers"},{"location":"tutorials/organization/#reference-material","text":"Reference material can be found in the datasheets/ and schematic/ folders. The layout of these directories match that demos/ , where the first layer of folders are named after the microcontroller or board they describe. These folders are updated with relevant documents for easy access for our developers and contributors.","title":"\ud83d\udcd1 Reference Material"}]}